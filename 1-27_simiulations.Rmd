---
title: "Adaptive Binning 1/21 Simulations"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE, warnings=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message = FALSE, error=FALSE)
setwd(path.expand("~/Dropbox/Duke/projects/FLAME-binning/Adaptive-Binning/"))
source("AB_MIPs.R")
library(ggplot2)
library(reshape2)
library(dbarts)
library(RColorBrewer)
require(dbarts)
require(MatchIt)
require(beepr)
require(cem)
require(tidyverse)
source("sims.R")
#source("AB_MIP.R")
set.seed(42069)
```

## 1-D Example MIQP-Variance

```{r "simple MIQP-V p=1", cache=TRUE, results='hide'}
n = 100
n_train = n
n_test = n
p = 1
x_train = matrix(rexp(n*p, 2), n, p)
y_train = rowSums(log(x_train)) + rnorm(n, 0, 1)
x_test = matrix(rexp(n*p, 2), n, p)
y_test = rowSums(log(x_test)) + rnorm(n, 0, 1)
z_train = rep(1, n)
z_test = rep(0, n_test)
simdata = matrix(NA, n, 3* p + 2)
simdata = data.frame(simdata)
names(simdata) = c(paste("x",1:p, sep=""), 
                   paste("a", 1:p, sep=""), 
                   paste("b", 1:p, sep=""), "y", "yest")
mip_outputs = list()
for (i in 1:n){
  print(i)
  xi = x_test[i,]
  
  t1 = proc.time()[3]
  xg = xgboost(data = x_train, label = y_train, nrounds = 50, verbose = F)
  fhat = predict(xg, newdata = x_test)
  mip_pars = setup_miqp_fhat(xi = xi, fhat = fhat,  x_test =  x_test, 
                             lambda=2, alpha=1, beta=0, m=1, M=1e5)
  t2 = proc.time()[3]
  sol = Rcplex(cvec=mip_pars$cvec, Amat=mip_pars$Amat, Qmat = mip_pars$Qmat,
               bvec=mip_pars$bvec, sense = mip_pars$sense,
               lb=mip_pars$lb, ub=mip_pars$ub,
               vtype = mip_pars$vtype, objsense = "max", control = list(trace=0))
  t3 = proc.time()[3]
  
  mip_out = recover_pars(sol, n_train, n_test, p)
  mip_outputs[[i]] = mip_out
  yest = mean(y_test[which(mip_out$w>=0.1)])
  simdata[i, ] = c(xi, mip_out$a, mip_out$b, y_test[i], yest)
  
  t4 = proc.time()[3]
  print(paste("Par generation took", round(t2 - t1, 1), 
              "seconds, solving mip took", round(t3 - t2, 1), "seconds",
              "total:", round(t4 - t1), "seconds"))
  
}
```

```{r "simple MIQP-V p=1 plot"}
ggplot(simdata) + 
  geom_rect(aes(xmin=a1, ymin=min(y), xmax=b1, ymax=max(y)), color="black", size=0.5, alpha=0.3, fill="grey") +
  geom_point(aes(x=x1, y=y), color='red', size=2) + 
  geom_point(aes(x=x1, y=yest), color="blue") + 
  geom_point(data=data.frame(x_train, y_train),aes(x=x_train, y=y_train), pch=18) +
  xlab("x") + ylab("y") + theme_bw() + 
  theme(legend.position = c(0.8,0.2), legend.background = element_rect(color="black", size=0.5),
        legend.title = element_blank())
```

## 2D Example MIQP-Variance

```{r "simple MIP-P p=2", cache=TRUE, results='hide'}
n = 100
n_train = 100
n_test = 100
p = 2
#x_train = matrix(rexp(n_train*p, 2), n_train, p)
#x_test = matrix(rexp(n_test*p, 2), n_test, p)
x_train = matrix(runif(n_train*p, 0, 1), n_train, p)
x_test = matrix(runif(n_test*p, 0, 1), n_test, p)
y_train = rowSums(log(x_train)) + rnorm(n_train, 0, 1)
y_test = rowSums(log(x_test)) + rnorm(n_test, 0, 1)
z_train = rep(1, n_train)
z_train[sample(1:n_train, n_train/2, replace = FALSE)] = 0
z_test = rep(0, n_test)
simdata = matrix(NA, n_test, 3* p + 2)
simdata = data.frame(simdata)
names(simdata) = c(paste("x",1:p, sep=""), 
                   paste("a", 1:p, sep=""), 
                   paste("b", 1:p, sep=""), "y", "yest")
t1 = proc.time()[3]
# xg = xgboost(data = x_train, label = y_train, nrounds = 50, verbose = F)
# fhat = predict(xg, newdata = x_test)
bart_fit = bart(x_train, y_train, x_test, keeptrees = T, verbose = 0)
fhat = colMeans(predict(bart_fit, test=x_test))
obj = rep(NA, n_test)
mip_outputs = list()
for (i in 1:n_test){
  message(paste("Matching unit", i, "of", n_test), "\r", appendLF = FALSE); flush.console()
  xi = x_test[i,]
  mip_pars = setup_miqp_fhat(xi = xi, fhat1 = fhat[-i], fhat0=fhat[-i], 
                             fhati1=fhat[i], fhati0=fhat[i], 
                             z_test=z_test[-i],
                             x_test =  x_test[-i, ], 
                             lambda1=3, lambda0=3, gamma1=5, gamma0=5, 
                             alpha=0, beta=1, m=1, M=1e5)
  sol = Rcplex(cvec=mip_pars$cvec, Amat=mip_pars$Amat, Qmat = mip_pars$Qmat,
               bvec=mip_pars$bvec, sense = mip_pars$sense,
               lb=mip_pars$lb, ub=mip_pars$ub,
               vtype = mip_pars$vtype, objsense = "max", control=list(trace=0))
  mip_out = recover_pars(sol, n_train, n_test-1, p)
  obj[i] = sol$obj
  mip_outputs[[i]] = mip_out
  yest = mean(y_test[-i][which(mip_out$w>=0.1)])
  simdata[i, ] = c(xi, mip_out$a, mip_out$b, y_test[i], yest)
}
print(paste("100 matches took", round(proc.time()[3] - t1, 1)))
```

```{r "simple MIP-P p=2 plot"}
ggplot(simdata) + 
  geom_rect(aes(xmin=a1, ymin=a2, xmax=b1, ymax=b2), fill="grey", 
            color="black", size=0.5, alpha=0.3) + 
  geom_point(aes(x=x1, y=x2, color=abs(yest - y)/mean(abs(y))), size=2) + 
  scale_color_gradient(low="blue", high="red") + 
  xlab("x1") + ylab("x2") +  labs(color="% Abs. error") +  theme_bw() + 
  theme(legend.position = c(0.9,0.5), 
        legend.background = element_rect(color="black", size=0.5))
#ggsave("01-21_p=2_plot.png")
```

```{r}
simdata %<>% mutate(id = 1:nrow(.))
p <- 
    ggplot(data = simdata) + 
    geom_rect_interactive(aes(xmin = a1, xmax = b1, ymin = a2, ymax = b2,
                              data_id = id),
              fill = 'grey', color = 'NA', 
              size = 0.5, alpha = 0) + 
    geom_point_interactive(aes(x = x1, y = x2, 
                               color=abs(yest - y)/mean(abs(y)), data_id = id)) + 
  scale_color_gradient(low="blue", high="red") +
  labs(x = 'x1', y = 'x2', color = "% Abs. Error") +
  theme_bw()
#E8C3D6
#D8CADE
#E9CCD1
girafe(ggobj = p,
         options = list(
           opts_hover(
           css = girafe_css(
             css = 'fill:orange',
             area = 'fill:#E8C3D6;fill-opacity:0.8',
             point = 'fill:black;r:5;stroke:black'
         ))))

# ggplot(simdata) + 
#   geom_rect_interactive(aes(xmin=a1, ymin=a2, xmax=b1, ymax=b2), fill="grey", 
#             color="black", size=0.5, alpha=0.3) + 
#   geom_point(aes(x=x1, y=x2, color=abs(yest - y)/mean(abs(y))), size=2) + 
#   scale_color_gradient(low="blue", high="red") + 
#   xlab("x1") + ylab("x2") +  labs(color="% Abs. error") +  theme_bw() + 
#   theme(legend.position = c(0.9,0.5), 
#         legend.background = element_rect(color="black", size=0.5))
#ggsave("01-21_p=2_plot.png")
```




## 2D Example With a Useless Covariate

```{r "simple MIP-P p=2", cache=TRUE, results='hide'}
n = 100
n_train = 100
n_test = 100
p = 2
x_train = matrix(runif(n_train*p, 0, 1), n_train, p)
y_train = (2*(x_train[, 1])) + rnorm(n_train, 0, 0.5)
x_test = matrix(runif(n_test*p, 0, 1), n_test, p)
y_test = (2*(x_test[, 1])) + rnorm(n_test, 0, 0.5)
z_train = rep(1, n_train)
z_train[sample(1:n_train, n_train/2, replace = FALSE)] = 0
z_test = rep(0, n_test)
simdata = matrix(NA, n_test, 3* p + 2)
simdata = data.frame(simdata)
names(simdata) = c(paste("x",1:p, sep=""), 
                   paste("a", 1:p, sep=""), 
                   paste("b", 1:p, sep=""), "y", "yest")
t1 = proc.time()[3]
# xg = xgboost(data = x_train, label = y_train, nrounds = 50, verbose = F)
# fhat = predict(xg, newdata = x_test)
lasso = glmnet(x_train, y_train, family="gaussian", alpha=1)
fhat = predict(lasso, newx = x_test)[,57]
mip_outputs = list()
for (i in 1:n_test){
  message(paste("Matching unit", i, "of", n_test), "\r", appendLF = FALSE); flush.console()
  xi = x_test[i,]
  mip_pars = setup_miqp_fhat(xi = xi, fhat1 = fhat[-i], fhat0=fhat[-i], 
                             fhati1=fhat[i], fhati0=fhat[i], 
                             z_test=z_test[-i],
                             x_test =  x_test[-i, ], 
                             lambda1=1, lambda0=1, gamma1=2, gamma0=2, 
                             alpha=-1, beta=0, m=1, M=1e5)
  sol = Rcplex(cvec=mip_pars$cvec, Amat=mip_pars$Amat, Qmat = mip_pars$Qmat,
               bvec=mip_pars$bvec, sense = mip_pars$sense,
               lb=mip_pars$lb, ub=mip_pars$ub,
               vtype = mip_pars$vtype, objsense = "max", control=list(trace=0))
  mip_out = recover_pars(sol, n_train, n_test-1, p)
  mip_outputs[[i]] = mip_out
  yest = mean(y_test[-i][which(mip_out$w>=0.1)])
  simdata[i, ] = c(xi, mip_out$a, mip_out$b, y_test[i], yest)
}
print(paste("100 matches took", round(proc.time()[3] - t1, 1)))
```

```{r "simple MIP-P p=2 plot"}
ggplot(simdata) + 
  geom_rect(aes(xmin=a1, ymin=a2, xmax=b1, ymax=b2), fill="grey", 
            color="black", size=0.5, alpha=0.3) + 
  geom_point(aes(x=x1, y=x2, color=abs(yest - y)/mean(abs(y))), size=2) + 
  scale_color_gradient(low="blue", high="red") + 
  xlab("x1") + ylab("x2") +  labs(color="% Abs. error") +  theme_bw() + 
  theme(legend.position = c(0.9,0.5), 
        legend.background = element_rect(color="black", size=0.5))
#ggsave("01-21_p=2_plot.png")
```


# Simulation 1

\begin{align*}
p = 2\\
x_{ij} &\sim Uniform(-3, 3)\\
e_i &= logit(\mathbf{x}_i^T\beta)\\
z_i &\sim Bernoulli(e_i)\\
\epsilon_i &\sim Normal(0, 1)\\
Y_i &= \alpha + z_i \mathbb{I}_{x_{i1} > 0.5}5 + \epsilon_i.
\end{align*}

```{r "sim 1", cache=T}
x_dgp = function(n, p){
  return(matrix(rexp(n*p, 2), n, p))
}
res = matching_sim(10, 200, 3, lambda=4, alpha=-1, beta=0, gamma=0, lambda0=1, lambda1=1, 
                   gamma0=2, gamma1=2, X_dgp=x_dgp, m = 2,
                   estimators = c("MIQP-Fhat", "Greedy", "CEM", "Full Matching" , 
                                  "Nearest Neighbor", "Prognostic", "Mahalanobis"))
res$estimator = factor(res$estimator, levels=c("MIQP-Fhat", "Greedy", "CEM", "Full Matching" , 
                                               "Nearest Neighbor", "Prognostic", "Mahalanobis"))
```

```{r "sim 1 plot"}
CATE_error_plot(res)
```


# Simulation 2

\begin{align*}
p = 10\\
x_{ij} &\sim Uniform(-3, 3)\\
e_i &= logit(\mathbf{x}_i^T\beta)\\
z_i &\sim Bernoulli(e_i)\\
\epsilon_i &\sim Normal(0, 1)\\
Y_i &= \alpha + z_i \mathbb{I}_{x_{i1} > 0.5}5 + \epsilon_i.
\end{align*}

```{r "sim 2", cache=T}
res = matching_sim(10, 200, 10)
res$estimator = factor(res$estimator, levels=c("MIP-Explain", "MIP-Predict", "MIQP-Variance", "Greedy", "CEM", "Full Matching" , "Nearest Neighbor", "Prognostic", "Mahalanobis"))
```

```{r "sim 2 plot"}
CATE_error_plot(res)
```


# Simulation Vittorio
```{r}
X_dgp = function(n, p){
  matrix(runif(n * p, min = 0, max = 5), n, p)
}
y_dgp <- function(x, z, eps, n_irrelevant = 8) {
  p <- ncol(x) - n_irrelevant

  # beta <- rnorm(p, 1.5, 0.15 ^ 0.5)
  beta_tilde <- 5
  Y <- 
    beta_tilde * z + eps
  
  # Y <- rowSums(sweep(x, 2, alpha, '*')) + z * rowSums(sweep(x, 2, beta, '*')) +  
  #   z * (x[, 1] * x[, 2] + x[, 1] * x[, 3] + x[, 2] * x[, 3]) + eps
  return(Y)
}
res <- matching_sim(10, 200, 5, X_dgp = X_dgp, y_dgp = y_dgp,
                   estimators =  c('MIQP-Fhat', 'Greedy', 'Nearest Neighbor', 'CEM', 'Full Matching', 'Prognostic', 'Mahalanobis'))
res$estimator %<>% factor(levels = c('Greedy', 'Nearest Neighbor', 'CEM', 'Full Matching', 'Prognostic', 'Mahalanobis'))
CATE_error_plot(res)
```


# Simulation 3

\begin{align*}
p = 3\\
x_{ij} &\sim exponential(0.5)\\
e_i &= logit(\mathbf{x}_i^T\beta)\\
z_i &\sim Bernoulli(e_i)\\
\epsilon_i &\sim Normal(0, 1)\\
Y_i &= \alpha + z_i \mathbb{I}_{x_{i1} > 0.5}5 + \epsilon_i.
\end{align*}

```{r "sim 3", cache=T}
X_dgp = function(n, p){
  matrix(runif(n * p, min = 0, max = 5), n, p)
}
y_dgp <- function(x, z, eps) {
  p <- ncol(x) - 3 # 3 irrelevant covariates
  alpha <- rnorm(p, 10 * sample(c(-1, 1), 1), 1)
  beta <- rnorm(p, 1.5, 0.15 ^ 0.5)
  Y <- rowSums(sweep(x, 2, alpha, '*')) + z * rowSums(sweep(x, 2, beta, '*')) +  
    z * (x[, 1] * x[, 2] + x[, 1] * x[, 3] + x[, 2] * x[, 3]) + eps
  return(Y)
}
res = matching_sim(10, 200, 6, X_dgp = X_dgp, y_dgp = y_dgp,
                   estimators =  c('MIQP-Fhat', 'Greedy', 'Nearest Neighbor', 'CEM', 'Full Matching', 'Prognostic', 'Mahalanobis'))
res$estimator %<>% factor(levels = c('MIQP-Fhat', 'Greedy', 'Nearest Neighbor', 'CEM', 'Full Matching', 'Prognostic', 'Mahalanobis'))
CATE_error_plot(res)
```



# Simulation 4

\begin{align*}
p = 3\\
x_{ij} &\sim uniform(0.5)\\
e_i &= logit(\mathbf{x}_i^T\beta)\\
z_i &\sim Bernoulli(e_i)\\
\epsilon_i &\sim Normal(0, 1)\\
\mathbf{B} &= diag([0, 2, 1])\\
Y_i &= 2 + 5z_i + z_i\mathbf{x}^T\mathbf{B}\mathbf{x} + \epsilon_i.
\end{align*}

```{r "sim 4", cache=T}
y_dgp = function(X, Z, eps){
  B = diag(c(0, 2, 1))
  HTE = (Z * apply(X, 1, function(x) x %*% B %*% x))
  return(2 + 5 * Z + HTE + eps)
}
x_dgp = function(n, p){
  return(matrix(runif(n*p, 0, 1), n, p))
}
# res = matching_sim(10, 200, 3, y_dgp=y_dgp,lambda=4, alpha=2, beta=0, gamma=0, m=2)
# res$estimator = factor(res$estimator, levels=c("MIP-Explain", "MIP-Predict", "MIQP-Variance", 
#                                                "Greedy", "CEM", "Full Matching" , "Nearest Neighbor", 
#                                                "Prognostic", "Mahalanobis"))
res = matching_sim(10, 200, 3, lambda=4, alpha=-2, beta=0, gamma=0, y_dgp = y_dgp, X_dgp = x_dgp,
                   lambda0=1, lambda1=1, gamma1=2, gamma0=2, m=2,
                   estimators = c("MIQP-Fhat", "Greedy", "CEM", "Full Matching" , 
                                  "Nearest Neighbor", "Prognostic", "Mahalanobis"))
res$estimator = factor(res$estimator, levels=c("MIQP-Fhat", "Greedy", "CEM", "Full Matching" , 
                                               "Nearest Neighbor", "Prognostic", "Mahalanobis"))
```

```{r "sim 4 plot"}
CATE_error_plot(res)
```


# Simulation 5

\begin{align*}
p = 10\\
x_{ij} &\sim uniform(0.5)\\
e_i &= logit(\mathbf{x}_i^T\beta)\\
z_i &\sim Bernoulli(e_i)\\
\epsilon_i &\sim Normal(0, 1)\\
\mathbf{B} &= diag([0, 2, 1, 0, 0, 1, 1, 2, 3, 0])\\
Y_i &= 2 + 5z_i + z_i\mathbf{x}_i^T\mathbf{B}\mathbf{x}_i + \epsilon_i.
\end{align*}

```{r "sim 5", cache=T}
HTE_dgp = function(X, Z){
  B = diag(c(0, 2, 1, 0, 0, 1, 1, 2, 3, 0))
  return(Z * apply(X, 1, function(x) x %*% B %*% x))
}
y_dgp = function(X, Z, HTE){
  return(2 + 5 * Z + HTE + rnorm(nrow(X), 0, 1))
}
res = matching_sim(10, 200, 10, HTE_dgp = HTE_dgp, y_dgp=y_dgp)
res$estimator = factor(res$estimator, levels=c("MIP-Explain", "MIP-Predict", "MIQP-Variance", 
                                               "Greedy", "CEM", "Full Matching" , "Nearest Neighbor", 
                                               "Prognostic", "Mahalanobis"))
```

```{r "sim 5 plot"}
CATE_error_plot(res)
```


# Simulation 6

\begin{align*}
p = 3\\
x_{ij} &\sim uniform(0.5)\\
e_i &= logit(\mathbf{x}_i^T\beta)\\
z_i &\sim Bernoulli(e_i)\\
\epsilon_i &\sim Normal(0, 1)\\
\mathbf{B} &= diag([0, 2, 1])\\
Y_i &= 2 + 5z_i + z_i\mathbf{x}_i^T\mathbf{B}\mathbf{x}_i + \mathbf{x}_i^t\gamma + \epsilon_i.
\end{align*}

```{r "sim 6", cache=T}
y_dgp = function(X, Z, eps){
  gamma = c(2,0,1)
  B = diag(c(0,2,1))
  return(2 + 5 * Z + Z * apply(X, 1, function(x) x %*% B %*% x) + as.matrix(X) %*% gamma + eps)
}
res = matching_sim(10, 200, 3, y_dgp=y_dgp)
res$estimator = factor(res$estimator, levels=c("MIP-Explain", "MIP-Predict", "MIQP-Variance", 
                                               "Greedy", "CEM", "Full Matching" , "Nearest Neighbor", 
                                               "Prognostic", "Mahalanobis"))
```

```{r "sim 6  plot"}
CATE_error_plot(res)
```



# Simulation 7

\begin{align*}
p = 5\\
x_{ij} &\sim uniform(0.5)\\
e_i &= logit(\mathbf{x}_i^T\beta)\\
z_i &\sim Bernoulli(e_i)\\
\epsilon_i &\sim Normal(0, 1)\\
\mathbf{B} &= diag([0, 2, 1])\\
Y_i &= 2 + 5z_i + z_i\mathbf{x}_i^T\mathbf{B}\mathbf{x}_i + \mathbf{x}_i^t\gamma + \epsilon_i.
\end{align*}

```{r "sim 7", cache=T}
x_dgp = function(n, p){
  return(matrix(runif(n*p, 0, 1), n, p))
}
y_dgp = function(X, Z, eps){
  HTE = 10 * sin(pi * X[, 1]*X[, 2]) + 20 * (X[, 3] - 0.5)^2 + 10 * X[, 4] + 5 * X[, 5]
  return (2 + HTE + Z*5 + eps)
}
res = matching_sim(10, 200, 5, lambda=4, alpha=-2, beta=0, gamma=0, y_dgp = y_dgp, X_dgp = x_dgp,
                   lambda0=1, lambda1=1, gamma1=2, gamma0=2, m=2,
                   estimators = c("MIQP-Fhat", "Greedy", "CEM", "Full Matching" , 
                                  "Nearest Neighbor", "Prognostic", "Mahalanobis"))
res$estimator = factor(res$estimator, levels=c("MIQP-Fhat","Greedy", "CEM", "Full Matching" , "Nearest Neighbor", 
                                               "Prognostic", "Mahalanobis"))
```

```{r "sim 7  plot"}
CATE_error_plot(res)
```


# Hyperparam Comparisons

```{r "hp comparison", cache=TRUE}
lambdas = 1:5
alphas = -5:5
simdata = NULL
for(lambda in lambdas){
  for (alpha in alphas){
    res = matching_sim(5 , 100, p=3, alpha=alpha, lambda=lambda)
    res = summarize_CATEs(res)
    simdata = rbind(simdata, data.frame(res, lambda=rep(lambda, nrow(res)), alpha=rep(alpha, nrow(res))))
  }
}
```

```{r "hp plot"}
ggdata =simdata[simdata$estimator %in% c("MIP-Explain", "MIP-Predict", "MIQP-Variance"), ]
ggplot(ggdata) + geom_point(aes(x=alpha, y=MSE, color=estimator)) + facet_grid(lambda~.)
```


# MG Analysis

## DGP 1

```{r "MG analysis", cache=TRUE}
c(df, HTE_true) %<-% simulate_data(200, 3)
c(df, f, n, n_train, p,
    train_df, train_covs, train_control, train_treated,
    test_df, test_covs, test_control, test_treated, 
    n_test_control, n_test_treated, 
    bart_fit, counterfactuals) %<-% estimator_inputs(df, 100, 200)
c(greedy_cates, greedy_bins) %<-% est_greedy(train_df, test_df, test_covs, test_control, test_treated,
                                             n_test_treated, 3, bart_fit)
c(miqp_cates, miqp_bins) %<-% est_MIQP_fhat(test_df, test_treated, n_test_treated, test_covs, bart_fit, 
                                            n_train, p, lambda=3, alpha=0, m=2)

miqp_cates2 = rep(NA, n_test_treated)
for (i in 1:n_test_treated){
  mg = make_mg(test_covs, miqp_bins[i,,1], miqp_bins[i,,2])
  miqp_cates2[i] = mean(test_df$Y[mg][test_df$treated[mg]]) - mean(test_df$Y[mg][!test_df$treated[mg]])
}

HTE_tt = HTE_true[test_treated]

ge = abs(HTE_tt - greedy_cates)
me = abs(HTE_tt - miqp_cates)
me2 = abs(miqp_cates2 - HTE_tt)

mip_pars =  setup_miqp_variance(xi = as.numeric(test_covs[i, ]),
                                    y_train = train_df$Y,
                                    x_train = train_covs,
                                    z_train = train_df$treated,
                                    x_test = as.matrix(test_covs[test_df$treated==0, ]),  
                                    alpha=alpha, lambda=lambda, m=m, M=M)
sol <- do.call(Rcplex, c(mip_pars, list(objsense="max", control=list(trace=0))))
mip_out = recover_pars(sol, nrow(train_df), sum(test_df$treated==0), p)
    
```


## DGP 2
```{r "MG analysis", cache=TRUE}
p=2
y_dgp = function(X, Z, eps){
  ind = (X[, 1] > 0.5  & X[, 2] > 0.5)
  return(1 + Z * 5 + ind * 3 + eps)
}
x_dgp = function(n, p){
  return(matrix(runif(n*p, 0, 1), n, p))
}
e_dgp = function(X){
  ind = (X[, 1] > 0.5  & X[, 2] > 0.5)
  return(ind * 0.5)
}
c(df, HTE) %<-% simulate_data(200, 3, y_dgp = y_dgp, X_dgp=x_dgp)
c(df, f, n, n_train, p,
    train_df, train_covs, train_control, train_treated,
    test_df, test_covs, test_control, test_treated, 
    n_test_control, n_test_treated, 
    bart_fit, counterfactuals) %<-% estimator_inputs(df, 100, 200)
HTE_test_treated = HTE[test_treated]
c(greedy_cates, greedy_bins) %<-% est_greedy(train_df, test_df, test_covs, test_control, test_treated,
                                             n_test_treated, 3, bart_fit)
c(miqp_cates, miqp_bins) %<-% est_MIQP_fhat(test_df, test_treated, n_test_treated, test_covs, bart_fit, 
                                            n_train, p, 
                                            lambda0=1, lambda1=1, gamma0=0.5, gamma1=0.5,
                                            alpha=-1, beta=2, m=1)

miqp_mq = rep(NA, n_test_treated)
greedy_mq = rep(NA, n_test_treated)
for (i in 1:n_test_treated){
  mg = make_mg(test_covs, miqp_bins[i,,1], miqp_bins[i,,2])
  miqp_mq[i] = mean(abs(colMeans(test_covs[mg, ][test_df$treated[mg],]) - 
                          colMeans(test_covs[mg, ][!test_df$treated[mg],])))
  mg = make_mg(test_covs, greedy_bins[i,,1], greedy_bins[i,,2])
  greedy_mq[i] = mean(abs(colMeans(test_covs[mg, ][test_df$treated[mg],]) - 
                          colMeans(test_covs[mg, ][!test_df$treated[mg],])))
}

ge = abs(HTE_test_treated - greedy_cates)
me = abs(HTE_test_treated - miqp_cates)

print(mean(me))

mip_pars =  setup_miqp_variance(xi = as.numeric(test_covs[i, ]),
                                    y_train = train_df$Y,
                                    x_train = train_covs,
                                    z_train = train_df$treated,
                                    x_test = as.matrix(test_covs[test_df$treated==0, ]),  
                                    alpha=alpha, lambda=lambda, m=m, M=M)
sol <- do.call(Rcplex, c(mip_pars, list(objsense="max", control=list(trace=0))))
mip_out = recover_pars(sol, nrow(train_df), sum(test_df$treated==0), p)
    
```


## Bins

```{r "Bins"}
p=2
y_dgp = function(X, Z, eps){
  ind = (X[, 1] > 0.5  & X[, 2] > 0.5)
  return(1 + Z * 5 + ind * 3 + eps)
}
x_dgp = function(n, p){
  return(matrix(runif(n*p, 0, 1), n, p))
}
c(df, HTE) %<-% simulate_data(200, 3, y_dgp = y_dgp, X_dgp=x_dgp)
c(df, f, n, n_train, p,
    train_df, train_covs, train_control, train_treated,
    test_df, test_covs, test_control, test_treated, 
    n_test_control, n_test_treated, 
    bart_fit, counterfactuals) %<-% estimator_inputs(df, 100, 200)
HTE_test_treated = HTE[test_treated]
mip_out <- est_MIQP_fhat(test_df, test_treated, n_test_treated, test_covs, bart_fit, 
                                            n_train, p, 
                                            lambda0=1, lambda1=1, gamma0=0.5, gamma1=0.5,
                                            alpha=-1, beta=2, m=1)
c(miqp_cates, miqp_bins) %<-% mip_out

me = abs(HTE_test_treated - miqp_cates)
print(mean(me))

bin_plot(mip_out, test_df, 1, 2, 0.5, 1, 0.5, 1)
```



```{r "Bins2"}
p=2
y_dgp = function(X, Z, eps){
  ind = (X[, 1] > 0.1 & X[, 1] < 0.6 & X[, 2] > 0.4 & X[, 2] < 0.8)
  return(1 + Z * 5 + ind * 5 + eps)
}
x_dgp = function(n, p){
  return(matrix(runif(n*p, 0, 1), n, p))
}
c(df, HTE) %<-% simulate_data(200, p, y_dgp = y_dgp, X_dgp=x_dgp)
c(df, f, n, n_train, p,
    train_df, train_covs, train_control, train_treated,
    test_df, test_covs, test_control, test_treated, 
    n_test_control, n_test_treated, 
    bart_fit, counterfactuals) %<-% estimator_inputs(df, 100, 200)
HTE_test_treated = HTE[test_treated]
mip_out <- est_MIQP_fhat(test_df, test_treated, n_test_treated, test_covs, bart_fit, 
                                            n_train, p, 
                                            lambda0=1, lambda1=1, gamma0=1, gamma1=1,
                                            alpha=0, beta=3, m=1)
c(miqp_cates, miqp_bins) %<-% mip_out

me = abs(HTE_test_treated - miqp_cates)
print(mean(me))

fhat1 = predict(bart_fit, newdata = as.matrix(cbind(test_covs, treated=1)))
fhat0 = predict(bart_fit, newdata = as.matrix(cbind(test_covs, treated=0)))
bcates = fhat1[test_treated] - fhat0[test_treated]
be = mean(abs(HTE_test_treated - bcates))
print(be)

bin_plot(miqp_bins, test_df, 1, 2, 0.1, 0.6, 0.4, 0.8)
```


## True F

```{r "Bins2"}
generate_grid = function(xi, test_covs, d){
  n = nrow(test_covs)
  p = ncol(test_covs)
  grid = NULL
  for (k in 1:n){
    xk = test_covs[k, ]
    means = (xi + xk)/2
    for(j in 1:p){
      grdj = seq(min(xi[j], xk[j]), max(xi[j], xk[j]), length.out = d)
      xgrdj = matrix(rep(means, d), d, p, byrow=T)
      xgrdj[, j] = grdj
      grid = rbind(grid, xgrdj)
    }
  }
  return(grid)
}


p=2
y_dgp = function(X, Z, eps){
  ind = (X[, 1] > 0.1 & X[, 1] < 0.6 & X[, 2] > 0.4 & X[, 2] < 0.8)
  return(1 + Z * 5 + ind * 5 + eps)
}
x_dgp = function(n, p){
  return(matrix(runif(n*p, 0, 1), n, p))
}
c(df, HTE) %<-% simulate_data(200, p, y_dgp = y_dgp, X_dgp=x_dgp)
c(df, f, n, n_train, p,
    train_df, train_covs, train_control, train_treated,
    test_df, test_covs, test_control, test_treated, 
    n_test_control, n_test_treated, 
    bart_fit, counterfactuals) %<-% estimator_inputs(df, 100, 200)
HTE_test_treated = HTE[test_treated]

alpha=0
lambda0=1
lambda1=1
gamma0=2
gamma1=2
beta=2
m=1
M=1e5
mip_cates = vector('numeric', n_test_treated)
mip_bins = array(NA, c(n_test_treated, p, 2))
# fhat1 = predict(bart_fit, newx=as.matrix(cbind(test_covs, treated=1)))
# fhat1 = fhat1[ ,ncol(fhat1)]
# fhat0 = predict(bart_fit, newx=as.matrix(cbind(test_covs, treated=0)))
# fhat0 = fhat0[, ncol(fhat0)]
# fhat1 = predict(bart_fit, newdata=as.matrix(cbind(test_covs, treated=1)))
# fhat0 = predict(bart_fit, newdata=as.matrix(cbind(test_covs, treated=0)))
ftrue1 = y_dgp(test_covs, 1, 0)
ftrue0 = y_dgp(test_covs, 0, 0)
message("Running MIQP-Fhat")
for (l in 1:n_test_treated){
  i = test_treated[l]
  message(paste("Matching unit", l, "of", n_test_treated), "\r", appendLF = FALSE); flush.console()
  
  mip_pars =  setup_miqp_fhat(xi = as.numeric(test_covs[i, ]),
                              x_test = as.matrix(test_covs[-i, ]),
                              z_test = test_df$treated[-i],
                              fhati1=ftrue1[i],
                              fhati0=ftrue0[i],
                              fhat1=ftrue1[-i],
                              fhat0=ftrue0[-i], 
                              alpha=alpha, lambda0=lambda0, lambda1=lambda1,
                              gamma0=gamma0, gamma1=gamma1, beta=beta, m=m, M=M)
  sol <- do.call(Rcplex, c(mip_pars, list(objsense="max", control=list(trace=0))))
  mip_out = recover_pars(sol, n_train, nrow(test_covs), p)
  
  mip_bins[l, ,1] = mip_out$a
  mip_bins[l, ,2] = mip_out$b
  #mip_cates[l] = test_df$Y[i] - mean(test_df$Y[test_df$treated==0][mip_out$w>=0.1])

  mg = make_mg(test_covs, mip_out$a, mip_out$b)
  #mip_cates[l] = mean(test_df$Y[mg][test_df$treated[mg]]) - mean(test_df$Y[mg][!test_df$treated[mg]])
  mip_cates[l] = test_df$Y[i] - mean(test_df$Y[mg][!test_df$treated[mg]])
}
message("\n")


me = abs(HTE_test_treated - mip_cates)
print(mean(me))

fhat1 = predict(bart_fit, newdata = as.matrix(cbind(test_covs, treated=1)))
fhat0 = predict(bart_fit, newdata = as.matrix(cbind(test_covs, treated=0)))
bcates = fhat1[test_treated] - fhat0[test_treated]
be = mean(abs(HTE_test_treated - bcates))
print(be)

bin_plot(mip_bins, test_df, 1, 2, 0.1, 0.6, 0.4, 0.8)

```


## Grid

```{r "Bins2"}
# generate_grid = function(xi, test_covs, d){
#   n = nrow(test_covs)
#   p = ncol(test_covs)
#   grid = NULL
#   for (k in 1:n){
#     xk = test_covs[k, ]
#     means = (xi + xk)/2
#     for(j in 1:p){
#       grdj = seq(min(xi[j], xk[j]), max(xi[j], xk[j]), length.out = d)
#       xgrdj = matrix(rep(means, d), d, p, byrow=T)
#       xgrdj[, j] = grdj
#       grid = rbind(grid, xgrdj)
#     }
#   }
#   # The grid is mysteriously a list because R is a very good language 
#   grid = (apply(grid,2, unlist))
#   colnames(grid) = colnames(test_covs)
#   return(grid)
# }


p=2
y_dgp = function(X, Z, eps){
  ind = (X[, 1] > 0.1 & X[, 1] < 0.6 & X[, 2] > 0.4 & X[, 2] < 0.8)
  return(1 + Z * 5 + ind * 5 + eps)
}
x_dgp = function(n, p){
  return(matrix(runif(n*p, 0, 1), n, p))
}
c(df, HTE) %<-% simulate_data(200, p, y_dgp = y_dgp, X_dgp=x_dgp)
c(df, f, n, n_train, p,
    train_df, train_covs, train_control, train_treated,
    test_df, test_covs, test_control, test_treated, 
    n_test_control, n_test_treated, 
    bart_fit, counterfactuals) %<-% estimator_inputs(df, 100, 200, black_box = 'xgb')
HTE_test_treated = HTE[test_treated]

alpha=0
lambda0=0
lambda1=0
gamma0=2
gamma1=2
beta=2
m=1
M=1e5
mip_cates = vector('numeric', n_test_treated)
mip_bins = array(NA, c(n_test_treated, p, 2))
# fhat1 = predict(bart_fit, newx=as.matrix(cbind(test_covs, treated=1)))
# fhat1 = fhat1[ ,ncol(fhat1)]
# fhat0 = predict(bart_fit, newx=as.matrix(cbind(test_covs, treated=0)))
# fhat0 = fhat0[, ncol(fhat0)]
message("Running MIQP-Fhat")
for (l in 1:n_test_treated){
  i = test_treated[l]
  message(paste("Matching unit", l, "of", n_test_treated), "\r", appendLF = FALSE); flush.console()
  
  grid = generate_grid(test_covs[i, ], test_covs[-i, ], 3)
  fhat1 = predict(bart_fit, newdata=as.matrix(cbind(grid, treated=1)))
  fhat0 = predict(bart_fit, newdata=as.matrix(cbind(grid, treated=0)))
  fhati1 = predict(bart_fit, newdata=as.matrix(cbind(test_covs, treated=1)))[i]
  fhati0 = predict(bart_fit, newdata=as.matrix(cbind(test_covs, treated=0)))[i]
  mip_pars =  setup_miqp_fhat(xi = as.numeric(test_covs[i, ]),
                              x_test = grid,
                              z_test = rep(1, nrow(grid)),
                              fhati1=fhati1,
                              fhati0=fhati0,
                              fhat1=fhat1,
                              fhat0=fhat0, 
                              alpha=alpha, lambda0=lambda0, lambda1=lambda1,
                              gamma0=gamma0, gamma1=gamma1, beta=beta, m=m, M=M)
  sol <- do.call(Rcplex, c(mip_pars, list(objsense="max", control=list(trace=0))))
  mip_out = recover_pars(sol, n_train, nrow(test_covs), p)
  
  mip_bins[l, ,1] = mip_out$a
  mip_bins[l, ,2] = mip_out$b
  #mip_cates[l] = test_df$Y[i] - mean(test_df$Y[test_df$treated==0][mip_out$w>=0.1])

  mg = make_mg(test_covs, mip_out$a, mip_out$b)
  #mip_cates[l] = mean(test_df$Y[mg][test_df$treated[mg]]) - mean(test_df$Y[mg][!test_df$treated[mg]])
  mip_cates[l] = test_df$Y[i] - mean(test_df$Y[mg][!test_df$treated[mg]])
}
message("\n")


me = abs(HTE_test_treated - mip_cates)
print(mean(me))

fhat1 = predict(bart_fit, newdata = as.matrix(cbind(test_covs, treated=1)))
fhat0 = predict(bart_fit, newdata = as.matrix(cbind(test_covs, treated=0)))
bcates = fhat1[test_treated] - fhat0[test_treated]
be = mean(abs(HTE_test_treated - bcates))
print(be)

bin_plot(mip_bins, test_df, 1, 2, 0.1, 0.6, 0.4, 0.8)

```

## More debugging

```{r}
generate_grid = function(xi, test_covs, d){
  n = nrow(test_covs)
  p = ncol(test_covs)
  grid = NULL
  for (k in 1:n){
    xk = test_covs[k, ]
    means = (xi + xk)/2
    for(j in 1:p){
      grdj = seq(min(xi[j], xk[j]), max(xi[j], xk[j]), length.out = d)
      xgrdj = matrix(rep(means, d), d, p, byrow=T)
      xgrdj[, j] = grdj
      grid = rbind(grid, xgrdj)
    }
  }
  # The grid is mysteriously now a list because R is a very good language 
  grid = (apply(grid,2, unlist))
  colnames(grid) = colnames(test_covs)
  return(grid)
}

y_dgp_quadratic <- function(x, z, eps) {
  beta_tilde <- 2
  gamma_tilde <- 1
  Y <-
    beta_tilde * rowSums((x - 0.5) ^ 2) * z +
    gamma_tilde * rowSums((x - 0.5) ^ 2) + eps
  return(Y)
}

y_dgp_linear_irr <- function(x, z, eps) {
  beta_tilde <- 3
  gamma_tilde <- 3
  Y <- 
    beta_tilde * x[, 1] * z +
    gamma_tilde * rowSums(x) + eps
  return(Y)
}

y_dgp_constant_irr <- function(x, z, eps) {
  confounding <- rowSums(x)
  treatment <- 1
  beta_tilde <- 5
  gamma_tilde <- 2
  Y <- 
    beta_tilde * treatment * z +
    gamma_tilde * confounding + eps
  return(Y)
}

y_dgp_simple <- function(x, z, eps) {
  beta_tilde <- 3
  gamma_tilde <- 2
  Y <- beta_tilde * z + eps
  return(Y)
}

y_dgp_box = function(X, Z, eps) {
  treatment = (X[, 1] > 0.25 & X[, 2] > 0.25 & X[, 3] > 0.25 & X[, 4] > 0.25 & X[, 5] > 0.25)
  confounding <- (X[, 1] > 0.25) + (X[, 2] > 0.25) + (X[, 3] > 0.25) + (X[, 4] > 0.25) + (X[, 5] > 0.25)
  return(confounding * 2 + 5 * Z * treatment + eps)
}

y_dgp_bart = function(X, Z, eps){
  Y<- 10 * sin(pi * X[, 1]*X[, 2]) + 20 *(X[, 3] - 0.5)^2 + 10*X[, 4] + 5*X[, 5] + 5 * X[, 3] * Z + eps
  return(Y)
}

x_dgp = function(n, p){
  return(matrix(rbinom(n * p, size = 1, prob = 0.3), n, p))
  # return(matrix(runif(n * p, min = 0, max = 1), nrow = n, ncol = p))
}
```


```{r}
set.seed(345)
########################################################
# Simulations
########################################################

# x_dgp <- function(Z, p_rel, p_irrel) {
#   n <- length(Z)
#   x_rel <-
#     runif(n * p_rel, min = 0, max = 1) %>%
#     matrix(nrow = n)
#   
#   # x_rel <- 
#   #   rbinom(n * p_rel, size = 1, prob = 0.5) %>%
#   #   matrix(nrow = n)
#   
#   x <- x_rel
#   for (i in 1:p_irrel) {
#     x %<>%
#       cbind(rbeta(n, shape1 = 1 + 8 * Z, shape2 = 9 - 8 * Z))
#   }
#   return(x)
# }

y_dgp_FLAME <- function(X, Z, eps, p_rel, U = 1, max_nonlinear = 5) {
  n <- nrow(X)
  
  s <- sample(c(-1, 1), size = p_rel, replace = TRUE)
  alpha <- rnorm(p_rel, 10 *s, 1)
  baseline <- X[, 1:p_rel] %*% alpha
  
  baseline <- sweep(X[, 1:p_rel], 2, 1:p_rel, '*') %*% rnorm(p_rel, 10, 1)
  
  beta <- rnorm(p_rel, 1.5, 0.15)
  linear_treated <- X[, 1:p_rel] %*% beta * Z
  
  interactions <- combn(1:max_nonlinear, 2)
  nonlinear_treated <- rep(0, n)
  for (i in 1:ncol(interactions)) {
    nonlinear_treated %<>% 
      add(X[, interactions[1, i]] * X[, interactions[2, i]])
  }
  nonlinear_treated <- nonlinear_treated * Z * U
  
  Y <- baseline + linear_treated + nonlinear_treated + eps
  
  return(Y)
}

y_dgp_MALTS <- function(X, Z, p_rel) {
  n <- length(Z)
  a <- sample(c(-1, 1), size = p_rel, replace = TRUE)
  beta <- a * 10 / (2 ^ c(1:p_rel))
  
  alpha <- rnorm(p_rel, 1, sqrt(0.5))
  # baseline <- X[, 1:p_rel] %*% alpha
  baseline <- sweep(X[, 1:p_rel], 2, 1:p_rel, '*') %*% rnorm(p_rel, 5, 1)
  
  linear_treated <- X[, 1:p_rel] %*% beta * Z
  
  interactions <- combn(1:p_rel, 2)
  nonlinear_treated <- rep(0, n)
  for (i in 1:ncol(interactions)) {
    nonlinear_treated %<>% 
      add(X[, interactions[1, i]] * X[, interactions[2, i]])
  }
  nonlinear_treated <- nonlinear_treated * Z
  
  return(baseline + linear_treated + nonlinear_treated)
}
  
y_dgp <- function(x, z, eps) {
  beta <- 3
  gamma <- 3
  confounding <- rowSums(x[, 1:2] ^ 2)
  Y <- beta * z + gamma * confounding + eps
}

x_dgp = function(n, p){
  # return(matrix(rbinom(n * p, size = 1, prob = 0.5), n, p))
  return(matrix(runif(n * p, min = 0, max = 1), nrow = n, ncol = p))
}

n <- 600
n_train <- 400
p <- 5
# p_rel <- 8
# p_irrel <- 2
# p <- p_rel + p_irrel
nsims <- 10

# nsims = 5
# n = 400
# n_train = 300


n_dgp <- length(all_y_dgp)
nsims = 5
n = 600
n_train = 200
alpha=0
lambda0=0
lambda1=0
gamma0=3
gamma1=3
beta=2
m=1
M=1e5
ratios <- c(1, 3, 5, 7, 10)
all_CATEs = NULL
# message(paste('Starting', sim_types[dgp], 'DGP', sep = ' '))
for (sim in 1:nsims) {
  CATEs <- NULL
  c(df, HTE) %<-% simulate_data(n, p, y_dgp = y_dgp, X_dgp=x_dgp)

  inputs <- estimator_inputs(df, n_train, n, 'BART', cv = TRUE)
  c(df, f, n, n_train, p,
      train_df, train_covs, train_control, train_treated,
      test_df, test_covs, test_control, test_treated, 
      n_test_control, n_test_treated, 
      bart_fit0, bart_fit1, counterfactuals) %<-% inputs
  HTE_test_treated = HTE[(n_train+1):n][test_df$treated]
  
  ftrue0 = y_dgp(test_covs, rep(0, n - n_train), rep(0, n - n_train))
  
  # Matching methods
  # 1-k matching methods 
  m_estimators <- c('Prognostic', 'GenMatch',
                    'Mahalanobis', 'Nearest Neighbor')
  
  for (r in ratios) {
    est_out <- 
      suppressWarnings(get_CATEs(inputs, 
                                 r, 
                                 m_estimators, 
                                 hyperparameters = as.list(rep(0, 10))))
    CATEs %<>% cbind(est_out$CATEs)
    # best match on true expected CF
    CATEs %<>% est_prog(test_df, ftrue0[test_treated], ratio = r)
  }
  
  # Not 1-k methods
   est_out <- 
      suppressWarnings(get_CATEs(inputs, 
                                 r, 
                                 c('Greedy', 'CEM', 'Full Matching'), 
                                 hyperparameters = as.list(rep(0, 10))))
   
   CATEs %<>% cbind(est_out$CATEs)
  
  
  # message(paste("Mean best CF error", mean(abs(CATEs[, 6] - HTE_test_treated))))
  
  ## BART
  fhat1 = colMeans(predict(bart_fit1, test = as.matrix(test_covs)))
  fhat0 = colMeans(predict(bart_fit0, test = as.matrix(test_covs)))
  # # fhat1 = colMeans(predict(bart_fit, test = as.matrix(cbind(test_covs, treated=1))))
  # # fhat0 = colMeans(predict(bart_fit, test = as.matrix(cbind(test_covs, treated=0))))
  bcates = (fhat1 - fhat0)
  CATEs %<>% bcates[test_treated]
  # message(paste("Mean BART error", mean(abs(CATEs[, 7] - HTE_test_treated))))
  
  ## BART overfit v1
  # ofcates = rep(NA, n_test_treated)
  # for (l in 1:n_test_treated){
  #   i = test_treated[l]
  #   match0 = which.min(abs(fhat0[i] - test_df$Y[test_control]))
  #   match1 = which.min(abs(fhat1[i] - test_df$Y[test_treated]))
  #   ofcates[l] = test_df$Y[test_treated][match1] - test_df$Y[test_control][match0]
  # }
  # CATEs = cbind(CATEs, ofcates)
  # 
  # ## BART overfit v2
  # ofcates2 = rep(NA, n_test_treated)
  # for (l in 1:n_test_treated){
  #   i = test_treated[l]
  #   match0 = which.min(abs(fhat0[i] - fhat0[test_control]))
  #   match1 = which.min(abs(fhat1[i] - fhat1[test_treated]))
  #   ofcates2[l] = test_df$Y[test_treated][match1] - test_df$Y[test_control][match0]
  # }
  # CATEs = cbind(CATEs, ofcates2)
  
  ## MIP
  # mip_cates = vector('numeric', n_test_treated)
  mip_cates_both = vector('numeric', n_test_treated)
  mip_bins = array(NA, c(n_test_treated, p, 2))
  message("Running MIQP-Fhat")
  for (l in 1:n_test_treated){
    i = test_treated[l]
    message(paste("Matching unit", l, "of", n_test_treated), "\r", appendLF = FALSE); flush.console()

    mip_pars =  setup_miqp_fhat(xi = as.numeric(test_covs[i, ]),
                                x_test = as.matrix(test_covs[-i, ]),
                                z_test = test_df$treated[-i],
                                fhati1=fhat1[i],
                                fhati0=fhat0[i],
                                fhat1=fhat1[-i],
                                fhat0=fhat0[-i],
                                alpha=alpha, lambda0=lambda0, lambda1=lambda1,
                                gamma0=gamma0/sd(fhat0), gamma1=gamma1/sd(fhat1),
                                beta=beta, m=m, M=M)
    sol <- do.call(Rcplex, c(mip_pars, list(objsense="max", control=list(trace=0))))
    mip_out = recover_pars(sol, n_train, nrow(test_covs), p)

    mip_bins[l, ,1] = mip_out$a
    mip_bins[l, ,2] = mip_out$b
  #
    mg = make_mg(test_covs, mip_out$a, mip_out$b)
    # mip_cates[l] = test_df$Y[i] - mean(test_df$Y[mg][!test_df$treated[mg]])
    mip_cates_both[l] = mean(test_df$Y[mg][test_df$treated[mg]]) - mean(test_df$Y[mg][!test_df$treated[mg]])
  }
  # message("")
  # CATEs <- cbind(CATEs, mip_cates)
  CATEs <- cbind(CATEs, mip_cates_both)
  # message(paste("Mean MIP error", mean(abs(CATEs[, 8] - HTE_test_treated), na.rm=T)))
  
  
  # fcates = format_CATEs(CATEs, true_CATE = HTE_test_treated,
  #                     estimators = c('Full Matching', 'Prognostic', 'GenMatch', 'CEM', 'Approximate',
  #                                    'Mahal', 'Nearest Neighbor',
  #                                    'Best CF', 'BART', 'MIP'))
  fcates <- 
    format_CATEs(CATEs, 
                 true_CATE = HTE_test_treated,
                 estimators = c('Prognostic1', 'GenMatch1', 'Mahal1', 'Nearest Neighbor1', 'Best CF1',
                                'Prognostic3', 'GenMatch3', 'Mahal3', 'Nearest Neighbor3', 'Best CF3',
                                'Prognostic5', 'GenMatch5', 'Mahal5', 'Nearest Neighbor5', 'Best CF5',
                                'Prognostic7', 'GenMatch7', 'Mahal7', 'Nearest Neighbor7', 'Best CF7',
                                'Prognostic10', 'GenMatch10', 'Mahal10', 'Nearest Neighbor10', 'Best CF10',
                                'Fast ABH', 'CEM', 'Full Matching', 'BART', 'MIP ABH'))
  
  all_CATEs <- rbind(all_CATEs, fcates)
  message(sprintf('%d of %d simulations completed', sim, nsims))
}
# print(summarize_CATEs(all_CATEs))
```

## Sim to end all sims
```{r}
set.seed(345)

x_dgp_cont <- function(n, p) {
  return(matrix(runif(n * p, min = 0, max = 1), nrow = n, ncol = p))
}

x_dgp_binary <- function(n, p) {
  return(matrix(rbinom(n * p, size = 1, prob = 0.5), nrow = n, ncol = p))
}

x_dgp_mixed <- function(n, p) {
  matrix(runif(n * p / 2, min = 0, max = 1), nrow = n, ncol = p / 2) %>%
    cbind(matrix(rbinom(n * p / 2, size = 1, prob = 0.5), nrow = n, ncol = p / 2)) %>%
    return()
}

y_dgp_none <- function(x, z, eps) {
  beta <- 3
  gamma <- 3
  confounding <- 0
  Y <- beta * z + gamma * confounding + eps
}

y_dgp_box <- function(x, z, eps) {
  beta <- 3
  gamma <- 3
  confounding <- (x[, 1] > 0.5 & x[, 2] > 0.5)
  Y <- beta * z + gamma * confounding + eps
}

y_dgp_linear <- function(x, z, eps) {
  beta <- 3
  gamma <- 3
  confounding <- rowSums(x)
  Y <- beta * z + gamma * confounding + eps
}

y_dgp_quad <- function(x, z, eps) {
  beta <- 3
  gamma <- 3
  confounding <- rowSums(x ^ 2)
  Y <- beta * z + gamma * confounding + eps
}

y_dgp_binary <- function(x, z, eps) {
  beta <- 3
  gamma <- 3
  confounding <- x[, 1]
  Y <- beta * z + gamma * confounding + eps
}

y_dgp_mixed <- function(x, z, eps) {
  beta <- 3
  gamma <- 3
  confounding <- 2 * x[, 1] + x[, 2]
  Y <- beta * z + gamma * confounding + eps
}

dgp_types <- c('None', 'Box', 'Linear', 'Quad', 
               'Quad Irrelevant', 'Binary Irrelevant', 'Mixed')

n_covs <- c(2, 2, 2, 2, 5, 2, 4)
cross_validate <- c(T, T, F, F, F, F, F)
y_dgp_funcs <- list(y_dgp_none, y_dgp_box, y_dgp_linear, y_dgp_quad,
                  y_dgp_quad, y_dgp_binary, y_dgp_mixed)
x_dgp_funcs <- list(x_dgp_cont, x_dgp_cont, x_dgp_cont, x_dgp_cont,
                    x_dgp_cont, x_dgp_binary, x_dgp_mixed)

n_dgps <- length(dgp_types)

n <- 600
n_train <- 400
nsims <- 10

alpha=0
lambda0=0
lambda1=0
gamma0=3
gamma1=3
beta=2
m=1
M=1e5

for (dgp in 1:n_dgps) {
  p <- n_covs[dgp]
  y_dgp <- y_dgp_funcs[[dgp]]
  x_dgp <- x_dgp_funcs[[dgp]]
  ratios <- c(1, 3, 5, 7, 10)
  all_CATEs <- NULL
  all_dfs <- vector(mode = 'list', length = nsims)
  for (sim in 1:nsims) {
    CATEs <- NULL
    c(df, HTE) %<-% 
      simulate_data(n_units = n, p = p, n_train = n_train, 
                    X_dgp = x_dgp, e_dgp = NULL, y_dgp = y_dgp)
    
    all_dfs[[sim]] <- df
  
    inputs <- estimator_inputs(df, n_train, n, 'BART', cv = cross_validate[dgp])
    c(df, f, n, n_train, p,
        train_df, train_covs, train_control, train_treated,
        test_df, test_covs, test_control, test_treated, 
        n_test_control, n_test_treated, 
        bart_fit0, bart_fit1, counterfactuals) %<-% inputs
    HTE_test_treated = HTE[(n_train+1):n][test_df$treated]
    
    ftrue0 <- y_dgp(test_covs, rep(0, n - n_train), rep(0, n - n_train))
    
    # Matching methods
    # 1-k matching methods 
    m_estimators <- c('Prognostic', 'GenMatch',
                      'Mahalanobis', 'Nearest Neighbor')
    
    for (r in ratios) {
      est_out <- 
        suppressWarnings(get_CATEs(inputs, 
                                   r, 
                                   m_estimators, 
                                   hyperparameters = as.list(rep(0, 10))))
      CATEs %<>% cbind(est_out$CATEs)
      # best match on true expected CF
      CATEs %<>% est_prog(test_df, ftrue0[test_treated], ratio = r)
    }
    
    # Not 1-k methods
     est_out <- 
        suppressWarnings(get_CATEs(inputs, 
                                   r, 
                                   c('Greedy', 'CEM', 'Full Matching'), 
                                   hyperparameters = as.list(rep(0, 10))))
     
     CATEs %<>% cbind(est_out$CATEs)
    
    ## BART
    fhat1 = colMeans(predict(bart_fit1, test = as.matrix(test_covs)))
    fhat0 = colMeans(predict(bart_fit0, test = as.matrix(test_covs)))
    bcates = (fhat1 - fhat0)
    CATEs %<>% bcates[test_treated]
    
    ## MIP
    mip_cates_both = vector('numeric', n_test_treated)
    mip_bins = array(NA, c(n_test_treated, p, 2))
    message("Running MIQP-Fhat")
    for (l in 1:n_test_treated){
      i = test_treated[l]
      message(paste("Matching unit", l, "of", n_test_treated), "\r", appendLF = FALSE); flush.console()
      mip_pars =  setup_miqp_fhat(xi = as.numeric(test_covs[i, ]),
                                  x_test = as.matrix(test_covs ),
                                  z_test = test_df$treated,
                                  fhati1=fhat1[i],
                                  fhati0=fhat0[i],
                                  fhat1=fhat1[-i],
                                  fhat0=fhat0[-i],
                                  alpha=alpha, lambda0=lambda0, lambda1=lambda1,
                                  gamma0=gamma0/sd(fhat0), gamma1=gamma1/sd(fhat1),
                                  beta=beta, m=m, M=M)
      sol <- do.call(Rcplex, c(mip_pars, list(objsense="max", control=list(trace=0))))
      mip_out = recover_pars(sol, n_train, nrow(test_covs), p)
  
      mip_bins[l, ,1] = mip_out$a
      mip_bins[l, ,2] = mip_out$b
      mg = make_mg(test_covs, mip_out$a, mip_out$b)
      mip_cates_both[l] = mean(test_df$Y[mg][test_df$treated[mg]]) - mean(test_df$Y[mg][!test_df$treated[mg]])
    }
    CATEs <- cbind(CATEs, mip_cates_both)
  
    fcates <- 
      format_CATEs(CATEs, 
                   true_CATE = HTE_test_treated,
                   estimators = c('Prognostic1', 'GenMatch1', 'Mahal1', 'Nearest Neighbor1', 'Best CF1',
                                  'Prognostic3', 'GenMatch3', 'Mahal3', 'Nearest Neighbor3', 'Best CF3',
                                  'Prognostic5', 'GenMatch5', 'Mahal5', 'Nearest Neighbor5', 'Best CF5',
                                  'Prognostic7', 'GenMatch7', 'Mahal7', 'Nearest Neighbor7', 'Best CF7',
                                  'Prognostic10', 'GenMatch10', 'Mahal10', 'Nearest Neighbor10', 'Best CF10',
                                  'Fast ABH', 'CEM', 'Full Matching', 'BART', 'MIP ABH'))
    
    all_CATEs <- rbind(all_CATEs, fcates)
    message(sprintf('%d of %d simulations completed', sim, nsims))
  }
  saveRDS(all_dfs, paste0(dgp_types[dgp], '_dfs.rds'))
  saveRDS(all_CATEs, paste0(dgp_types[dgp], '_CATEs.rds'))
}
```


# MIP -- Greedy
```{r}
overlap <- matrix(, nrow = n_test_treated, ncol = 2)
for (i in 1:n_test_treated) {
  mip_vec <- NULL
  greedy_vec <- NULL
  for (k in 1:nrow(test_df)) {
    if (all(test_covs[k, ] < mip_bins[i, , 2]) & 
        all(test_covs[k, ] > mip_bins[i, , 1])) {
      mip_vec %<>% c(k)
    }
    if (all(test_covs[k, ] < est_out$bins[['Greedy']][i, , 2]) & 
        all(test_covs[k, ] > est_out$bins[['Greedy']][i, , 1])) {
      greedy_vec %<>% c(k)
    }
  }
  overlap[i, 1] <- mean(mip_vec %in% greedy_vec)
  overlap[i, 2] <- mean(greedy_vec %in% mip_vec)
}
apply(overlap, 2, median, na.rm = TRUE)
```



## Bin viz
```{r}
n = 100
n_train = 200
n_test = 200
p = 2
#x_train = matrix(rexp(n_train*p, 2), n_train, p)
#x_test = matrix(rexp(n_test*p, 2), n_test, p)
x_train = matrix(runif(n_train*p, 0, 1), n_train, p)
x_test = matrix(runif(n_test*p, 0, 1), n_test, p)
y_train = 10 * rowSums(x_train ^ 2) + rnorm(n_train, 0, 1)
y_test = 10 * rowSums(x_test ^ 2) + rnorm(n_test, 0, 1)
z_train = rep(1, n_train)
z_train[sample(1:n_train, n_train/2, replace = FALSE)] = 0
z_test = rep(0, n_test)
simdata = matrix(NA, n_test, 3* p + 2)
simdata = data.frame(simdata)
names(simdata) = c(paste("x",1:p, sep=""), 
                   paste("a", 1:p, sep=""), 
                   paste("b", 1:p, sep=""), "y", "yest")
t1 = proc.time()[3]
# xg = xgboost(data = x_train, label = y_train, nrounds = 50, verbose = F)
# fhat = predict(xg, newdata = x_test)
bart_fit = bart(x_train, y_train, x_test, keeptrees = T, verbose = 0)
fhat = colMeans(predict(bart_fit, test=x_test))
obj = rep(NA, n_test)
mip_outputs = list()

# xi = x_test[i,]
#   mip_pars = setup_miqp_fhat(xi = xi, fhat1 = fhat[-i], fhat0=fhat[-i], 
#                              fhati1=fhat[i], fhati0=fhat[i], 
#                              z_test=z_test[-i],
#                              x_test =  x_test[-i, ], 
#                              lambda1=3, lambda0=3, gamma1=5, gamma0=5, 
#                              alpha=0, beta=1, m=1, M=1e5)
#   sol = Rcplex(cvec=mip_pars$cvec, Amat=mip_pars$Amat, Qmat = mip_pars$Qmat,
#                bvec=mip_pars$bvec, sense = mip_pars$sense,
#                lb=mip_pars$lb, ub=mip_pars$ub,
#                vtype = mip_pars$vtype, objsense = "max", control=list(trace=0))
#   mip_out = recover_pars(sol, n_train, n_test-1, p)
#   obj[i] = sol$obj
#   mip_outputs[[i]] = mip_out
#   yest = mean(y_test[-i][which(mip_out$w>=0.1)])
#   simdata[i, ] = c(xi, mip_out$a, mip_out$b, y_test[i], yest)
mip_bins = array(NA, c(n_test, p, 2))
for (i in 1:n_test){
  message(paste("Matching unit", i, "of", n_test), "\r", appendLF = FALSE); flush.console()
  xi = x_test[i,]
  mip_pars =  setup_miqp_fhat(xi = xi,
                               x_test = x_test[-i, ],
                                    z_test = z_test[-i],
                                    fhati1=fhat[i],
                                    fhati0=fhat[i],
                                    fhat1=fhat[-i],
                                    fhat0=fhat[-i],
                                    alpha=alpha, lambda0=lambda0, lambda1=lambda1,
                                    gamma0=gamma0/sd(fhat0), gamma1=gamma1/sd(fhat1),
                                    beta=beta, m=m, M=M)
  sol <- do.call(Rcplex, c(mip_pars, list(objsense="max", control=list(trace=0))))
  mip_out = recover_pars(sol, n_train, nrow(test_covs), p)
  obj[i] = sol$obj
  mip_outputs[[i]] = mip_out
  yest = mean(y_test[-i][which(mip_out$w>=0.1)])
  mip_bins[i, , 1] <- mip_out$a
  mip_bins[i, , 2] <- mip_out$b
  simdata[i, ] = c(xi, mip_out$a, mip_out$b, y_test[i], yest)
}
```

```{r}
bottom_left <- with(simdata, intersect(which(x1 < 0.25), which(x2 < 0.25))) %>% 
  sample(size = 1)
bottom_right <- with(simdata, intersect(which(x1 > 0.875), which(x2 < 0.25))) %>% 
  sample(size = 1)
top_left <- with(simdata, intersect(which(x2 > 0.875), which(x1 < 0.25))) %>% 
  sample(size = 1)
top_right <- with(simdata, intersect(which(x1 > 0.8), which(x2 > 0.8))) %>% 
  sample(size = 2)
# low_middle <- with(simdata, which((x1 > 0.25) &
#                                       (x1 < 0.50) &
#                                       (x2 > 0.25) &
#                                       (x2 < 0.5))) %>% 
#   sample(size = 1)
high_middle <- with(simdata, which((x1 > 0.5) & 
                                      (x1 < 0.75) &
                                      (x2 > 0.5) &
                                      (x2 < 0.75))) %>% 
  sample(size = 1)
# high_right_low_left <- with(simdata, which((x1 > 0.75) & 
#                                       (x2 > 0.5) &
#                                       (x2 < 0.75))) %>% 
#   sample(size = 1)
# high_left_low_right <- with(simdata, which((x2 > 0.75) &
#                                       (x1 > 0.5) &
#                                       (x1 < 0.75))) %>% 
#   sample(size = 1)
# to_plot <- c(bottom_left, bottom_right, top_left, top_right,
#              low_middle, high_middle, high_right_low_left, high_left_low_right)
to_plot <- c(bottom_left, bottom_right, top_left, top_right,
             high_middle)

grid_pts <-  
  expand.grid(seq(0, 1, length.out = 50),
              seq(0, 1, length.out = 50)) %>%
  as.data.frame() %>%
  `colnames<-`(c('X1', 'X2')) %>%
  mutate(y = 10 * (X1 ^ 2 + X2 ^ 2))
  

ggplot() + 
  geom_raster(data = grid_pts, aes(x = X1, y = X2, fill = y), 
                         interpolate = TRUE) + 
  geom_rect(data = simdata[to_plot, ],
            aes(xmin = a1, xmax = b1, ymin = a2, ymax = b2), 
            fill = 'NA', color = 'red', size = 0.5, alpha = 0.8) + 
  geom_point(data = simdata, aes(x = x1, y = x2)) + 
  geom_point(data = simdata[to_plot, ], aes(x = x1, y = x2), size = 5) + 
  scale_x_continuous(name = 'X1', breaks = c(0, 1), labels = c(0, 1), limits = c(-.05, 1.05)) +
  scale_y_continuous(name = 'X2', breaks = c(0, 1), labels = c(0, 1), limits = c(-.05, 1.05)) +
  theme_minimal() + 
  theme(legend.position = 'none', text = element_text(size = 20), axis.text.x = element_text(size = 20), axis.text.y = element_text(size = 20))
```

```{r}
simdata %<>% mutate(id = 1:nrow(.))
p <- 
    ggplot(data = simdata) + 
    geom_rect_interactive(aes(xmin = a1, xmax = b1, ymin = a2, ymax = b2,
                              data_id = id),
              fill = 'grey', color = 'NA', 
              size = 0.5, alpha = 0) + 
    geom_point_interactive(aes(x = x1, y = x2, data_id = id)) + 
  labs(x = 'x1', y = 'x2') +
  theme_bw()
#E8C3D6
#D8CADE
#E9CCD1
girafe(ggobj = p,
         options = list(
           opts_hover(
           css = girafe_css(
             css = 'fill:orange',
             area = 'fill:#E8C3D6;fill-opacity:0.8',
             point = 'fill:black;r:5;stroke:black'
         ))))

# testdf <- cbind(x_test, !as.logical(z_test), y_test) %>%
#   `colnames<-`(c('X1', 'X2', 'treated', 'outcome')) %>%
#   as.data.frame()
# bin_plot(mip_bins, testdf, 1, 2)
# 
# ggplot(simdata) + 
#   geom_rect(aes(xmin=a1, ymin=a2, xmax=b1, ymax=b2), fill="grey", 
#             color="black", size=0.5, alpha=0.3) + 
#   geom_point(aes(x=x1, y=x2), size=2) + 
#   xlab("x1") + ylab("x2") +  theme_minimal()
#ggsave("01-21_p=2_plot.png")

```


## FLAME Simulations
```{r}
x_dgp <- function(Z, p_rel, p_irrel) {
  n <- length(Z)
  x_rel <-
    runif(n * p_rel, min = 0, max = 1) %>%
    matrix(nrow = n)
  
  # x_rel <- 
  #   rbinom(n * p_rel, size = 1, prob = 0.5) %>%
  #   matrix(nrow = n)
  
  x <- x_rel
  for (i in 1:p_irrel) {
    x %<>%
      cbind(rbeta(n, shape1 = 1 + 8 * Z, shape2 = 9 - 8 * Z))
  }
  return(x)
}

y_dgp_FLAME <- function(X, Z, eps, U = 1, p_rel = 10, max_nonlinear = 5) {
  n <- nrow(X)
  
  s <- sample(c(-1, 1), size = p_rel, replace = TRUE)
  alpha <- rnorm(p_rel, 10 *s, 1)
  baseline <- X[, 1:p_rel] %*% alpha
  
  beta <- rnorm(p_rel, 1.5, 0.15)
  linear_treated <- X[, 1:p_rel] %*% beta * Z
  
  interactions <- combn(1:max_nonlinear, 2)
  nonlinear_treated <- rep(0, n)
  for (i in 1:ncol(interactions)) {
    nonlinear_treated %<>% 
      add(X[, interactions[1, i]] * X[, interactions[2, i]])
  }
  nonlinear_treated <- nonlinear_treated * Z * U
  
  Y <- baseline + linear_treated + nonlinear_treated + eps
  
  return(Y)
}

n <- 200
n_train <- 100
p_rel <- 10
p_irrel <- 20
nsims <- 10

all_CATEs <- NULL
for (sim in 1:nsims) {
  Z <- sample(c(0, 1), size = n, replace = TRUE)
  X <- x_dgp(Z, p_rel, p_irrel)
  eps <- rnorm(n, 0, sqrt(0.1))
  Y1 <- y_dgp_FLAME(X, rep(1, n), eps)
  Y0 <- y_dgp_FLAME(X, rep(0, n), eps)
  HTE <- Y1 - Y0
  Y <- Y1 * Z + Y0 * (1 - Z)
  df <- cbind(data.frame(X), data.frame(Y = Y, treated = as.logical(Z)))
  
  inputs <- estimator_inputs(df, n_train, n, 'BART', cv = FALSE)
    c(df, f, n, n_train, p,
        train_df, train_covs, train_control, train_treated,
        test_df, test_covs, test_control, test_treated, 
        n_test_control, n_test_treated, 
        bart_fit, counterfactuals) %<-% inputs
    HTE_test_treated = HTE[(n_train+1):n][test_df$treated]
    
    # Matching methods
    m_estimators <- c('Full Matching', 'Prognostic', 'CEM',
                      'Mahalanobis', 'Nearest Neighbor')
    est_out <- suppressWarnings(get_CATEs(inputs, m_estimators, hyperparameters = as.list(rep(0, 10))))
    CATEs = est_out$CATEs
    
    fcates = format_CATEs(CATEs, true_CATE = HTE_test_treated,
                        estimators = c('Full Matching', 'Prognostic', 'CEM',
                                       'Mahalanobis', 'Nearest Neighbor'))
    all_CATEs <- rbind(all_CATEs, fcates)
    message(sprintf('%d of %d simulations completed', sim, nsims))
}
CATE_scatter_plot(all_CATEs)
```


```{r}
saveRDS(all_BART_CATEs, 'sim_BART.rds')
saveRDS(all_box_CATEs, 'sim_box.rds')
saveRDS(all_const_conf_CATEs, 'sim_constant_conf.rds')
saveRDS(all_linear_CATEs, 'sim_linear.rds')
saveRDS(all_quad_CATEs, 'sim_quadratic.rds')
saveRDS(all_simple_CATEs, 'sim_constant.rds')
```

```{r}
require(cowplot)
bart_sim_plot <- CATE_error_plot(all_BART_CATEs)
ggsave(paste('new_sim_BART.png'),
       width = 10, height = 8, units = 'in', device = 'png', dpi = 300)
box_sim_plot <- CATE_error_plot(all_box_CATEs)
ggsave(paste('new_sim_box.png'),
       width = 10, height = 8, units = 'in', device = 'png', dpi = 300)
const_conf_sim_plot <- CATE_error_plot(all_const_conf_CATEs)
ggsave(paste('new_sim_constant_conf.png'),
       width = 10, height = 8, units = 'in', device = 'png', dpi = 300)
linear_sim_plot <- CATE_error_plot(all_linear_CATEs)
ggsave(paste('new_sim_linear.png'),
       width = 10, height = 8, units = 'in', device = 'png', dpi = 300)
quad_sim_plot <- CATE_error_plot(all_quad_CATEs)
ggsave(paste('new_sim_quad.png'),
       width = 10, height = 8, units = 'in', device = 'png', dpi = 300)
simple_sim_plot <- CATE_error_plot(all_simple_CATEs)
ggsave(paste('new_sim_simple.png'),
       width = 10, height = 8, units = 'in', device = 'png', dpi = 300)

plot_grid(simple_sim_plot, const_conf_sim_plot, box_sim_plot,
          linear_sim_plot, quad_sim_plot, bart_sim_plot,
          labels = c('Constant', 'Constant w/Confounding', 'Box',
                     'Linear', 'Quadratic', 'BART Function'))
ggsave('all_new_sims.png',
       width = 12, height = 10, units = 'in', device = 'png', dpi = 300)
```

```{r}
const <- readRDS('5_cov_simple.rds')
lin <- readRDS('5_cov_linear.rds')
quad <- readRDS('5_cov_quad.rds')

constplot <- CATE_error_plot(const)
linplot <- CATE_error_plot(lin)
quadplot <- CATE_error_plot(quad)

plot_grid(constplot, linplot, quadplot, 
          labels = c('Constant', 'Linear', 'Quadratic'))
```




