---
title: "Adaptive Binning 1/21 Simulations"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE, warnings=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message = FALSE, error=FALSE)
setwd("/home/marco/Dropbox/Duke/projects/FLAME-binning/Adaptive-Binning/")
source("AB_MIPs.R")
library(ggplot2)
library(reshape2)
library(dbarts)
library(RColorBrewer)
require(dbarts)
require(MatchIt)
require(beepr)
require(cem)
require(tidyverse)
source("sims.R")
#source("AB_MIP.R")
set.seed(42069)
```

## 1-D Example MIQP-Variance

```{r "simple MIQP-V p=1", cache=TRUE, results='hide'}
n = 100
n_train = n
n_test = n
p = 1
x_train = matrix(rexp(n*p, 2), n, p)
y_train = rowSums(log(x_train)) + rnorm(n, 0, 1)
x_test = matrix(rexp(n*p, 2), n, p)
y_test = rowSums(log(x_test)) + rnorm(n, 0, 1)
z_train = rep(1, n)
z_test = rep(0, n_test)
simdata = matrix(NA, n, 3* p + 2)
simdata = data.frame(simdata)
names(simdata) = c(paste("x",1:p, sep=""), 
                   paste("a", 1:p, sep=""), 
                   paste("b", 1:p, sep=""), "y", "yest")
mip_outputs = list()
for (i in 1:n){
  print(i)
  xi = x_test[i,]
  
  t1 = proc.time()[3]
  xg = xgboost(data = x_train, label = y_train, nrounds = 50, verbose = F)
  fhat = predict(xg, newdata = x_test)
  mip_pars = setup_miqp_fhat(xi = xi, fhat = fhat,  x_test =  x_test, 
                             lambda=2, alpha=1, beta=0, m=1, M=1e5)
  t2 = proc.time()[3]
  sol = Rcplex(cvec=mip_pars$cvec, Amat=mip_pars$Amat, Qmat = mip_pars$Qmat,
               bvec=mip_pars$bvec, sense = mip_pars$sense,
               lb=mip_pars$lb, ub=mip_pars$ub,
               vtype = mip_pars$vtype, objsense = "max", control = list(trace=0))
  t3 = proc.time()[3]
  
  mip_out = recover_pars(sol, n_train, n_test, p)
  mip_outputs[[i]] = mip_out
  yest = mean(y_test[which(mip_out$w>=0.1)])
  simdata[i, ] = c(xi, mip_out$a, mip_out$b, y_test[i], yest)
  
  t4 = proc.time()[3]
  print(paste("Par generation took", round(t2 - t1, 1), 
              "seconds, solving mip took", round(t3 - t2, 1), "seconds",
              "total:", round(t4 - t1), "seconds"))
  
}
```

```{r "simple MIQP-V p=1 plot"}
ggplot(simdata) + 
  geom_rect(aes(xmin=a1, ymin=min(y), xmax=b1, ymax=max(y)), color="black", size=0.5, alpha=0.3, fill="grey") +
  geom_point(aes(x=x1, y=y), color='red', size=2) + 
  geom_point(aes(x=x1, y=yest), color="blue") + 
  geom_point(data=data.frame(x_train, y_train),aes(x=x_train, y=y_train), pch=18) +
  xlab("x") + ylab("y") + theme_bw() + 
  theme(legend.position = c(0.8,0.2), legend.background = element_rect(color="black", size=0.5),
        legend.title = element_blank())

```

## 2D Example MIQP-Variance

```{r "simple MIP-P p=2", cache=TRUE, results='hide'}
n = 100
n_train = 100
n_test = 100
p = 2
#x_train = matrix(rexp(n_train*p, 2), n_train, p)
#x_test = matrix(rexp(n_test*p, 2), n_test, p)
x_train = matrix(runif(n_train*p, 0, 1), n_train, p)
x_test = matrix(runif(n_test*p, 0, 1), n_test, p)
y_train = rowSums(log(x_train)) + rnorm(n_train, 0, 1)
y_test = rowSums(log(x_test)) + rnorm(n_test, 0, 1)
z_train = rep(1, n_train)
z_train[sample(1:n_train, n_train/2, replace = FALSE)] = 0
z_test = rep(0, n_test)
simdata = matrix(NA, n_test, 3* p + 2)
simdata = data.frame(simdata)
names(simdata) = c(paste("x",1:p, sep=""), 
                   paste("a", 1:p, sep=""), 
                   paste("b", 1:p, sep=""), "y", "yest")
t1 = proc.time()[3]
# xg = xgboost(data = x_train, label = y_train, nrounds = 50, verbose = F)
# fhat = predict(xg, newdata = x_test)
bart_fit = bart(x_train, y_train, x_test, keeptrees = T, verbose = 0)
fhat = colMeans(predict(bart_fit, test=x_test))
obj = rep(NA, n_test)
mip_outputs = list()
for (i in 1:n_test){
  message(paste("Matching unit", i, "of", n_test), "\r", appendLF = FALSE); flush.console()
  xi = x_test[i,]
  mip_pars = setup_miqp_fhat(xi = xi, fhat1 = fhat[-i], fhat0=fhat[-i], 
                             fhati1=fhat[i], fhati0=fhat[i], 
                             z_test=z_test[-i],
                             x_test =  x_test[-i, ], 
                             lambda1=3, lambda0=3, gamma1=5, gamma0=5, 
                             alpha=0, beta=1, m=1, M=1e5)
  sol = Rcplex(cvec=mip_pars$cvec, Amat=mip_pars$Amat, Qmat = mip_pars$Qmat,
               bvec=mip_pars$bvec, sense = mip_pars$sense,
               lb=mip_pars$lb, ub=mip_pars$ub,
               vtype = mip_pars$vtype, objsense = "max", control=list(trace=0))
  mip_out = recover_pars(sol, n_train, n_test-1, p)
  obj[i] = sol$obj
  mip_outputs[[i]] = mip_out
  yest = mean(y_test[-i][which(mip_out$w>=0.1)])
  simdata[i, ] = c(xi, mip_out$a, mip_out$b, y_test[i], yest)
}
print(paste("100 matches took", round(proc.time()[3] - t1, 1)))
```

```{r "simple MIP-P p=2 plot"}
ggplot(simdata) + 
  geom_rect(aes(xmin=a1, ymin=a2, xmax=b1, ymax=b2), fill="grey", 
            color="black", size=0.5, alpha=0.3) + 
  geom_point(aes(x=x1, y=x2, color=abs(yest - y)/mean(abs(y))), size=2) + 
  scale_color_gradient(low="blue", high="red") + 
  xlab("x1") + ylab("x2") +  labs(color="% Abs. error") +  theme_bw() + 
  theme(legend.position = c(0.9,0.5), 
        legend.background = element_rect(color="black", size=0.5))
#ggsave("01-21_p=2_plot.png")
```

```{r}
simdata %<>% mutate(id = 1:nrow(.))
p <- 
    ggplot(data = simdata) + 
    geom_rect_interactive(aes(xmin = a1, xmax = b1, ymin = a2, ymax = b2,
                              data_id = id),
              fill = 'grey', color = 'NA', 
              size = 0.5, alpha = 0) + 
    geom_point_interactive(aes(x = x1, y = x2, 
                               color=abs(yest - y)/mean(abs(y)), data_id = id)) + 
  scale_color_gradient(low="blue", high="red") +
  labs(x = 'x1', y = 'x2', color = "% Abs. Error") +
  theme_bw()
#E8C3D6
#D8CADE
#E9CCD1
girafe(ggobj = p,
         options = list(
           opts_hover(
           css = girafe_css(
             css = 'fill:orange',
             area = 'fill:#E8C3D6;fill-opacity:0.8',
             point = 'fill:black;r:5;stroke:black'
         ))))

# ggplot(simdata) + 
#   geom_rect_interactive(aes(xmin=a1, ymin=a2, xmax=b1, ymax=b2), fill="grey", 
#             color="black", size=0.5, alpha=0.3) + 
#   geom_point(aes(x=x1, y=x2, color=abs(yest - y)/mean(abs(y))), size=2) + 
#   scale_color_gradient(low="blue", high="red") + 
#   xlab("x1") + ylab("x2") +  labs(color="% Abs. error") +  theme_bw() + 
#   theme(legend.position = c(0.9,0.5), 
#         legend.background = element_rect(color="black", size=0.5))
#ggsave("01-21_p=2_plot.png")
```




## 2D Example With a Useless Covariate

```{r "simple MIP-P p=2", cache=TRUE, results='hide'}
n = 100
n_train = 100
n_test = 100
p = 2
x_train = matrix(runif(n_train*p, 0, 1), n_train, p)
y_train = (2*(x_train[, 1])) + rnorm(n_train, 0, 0.5)
x_test = matrix(runif(n_test*p, 0, 1), n_test, p)
y_test = (2*(x_test[, 1])) + rnorm(n_test, 0, 0.5)
z_train = rep(1, n_train)
z_train[sample(1:n_train, n_train/2, replace = FALSE)] = 0
z_test = rep(0, n_test)
simdata = matrix(NA, n_test, 3* p + 2)
simdata = data.frame(simdata)
names(simdata) = c(paste("x",1:p, sep=""), 
                   paste("a", 1:p, sep=""), 
                   paste("b", 1:p, sep=""), "y", "yest")
t1 = proc.time()[3]
# xg = xgboost(data = x_train, label = y_train, nrounds = 50, verbose = F)
# fhat = predict(xg, newdata = x_test)
lasso = glmnet(x_train, y_train, family="gaussian", alpha=1)
fhat = predict(lasso, newx = x_test)[,57]
mip_outputs = list()
for (i in 1:n_test){
  message(paste("Matching unit", i, "of", n_test), "\r", appendLF = FALSE); flush.console()
  xi = x_test[i,]
  mip_pars = setup_miqp_fhat(xi = xi, fhat1 = fhat[-i], fhat0=fhat[-i], 
                             fhati1=fhat[i], fhati0=fhat[i], 
                             z_test=z_test[-i],
                             x_test =  x_test[-i, ], 
                             lambda1=1, lambda0=1, gamma1=2, gamma0=2, 
                             alpha=-1, beta=0, m=1, M=1e5)
  sol = Rcplex(cvec=mip_pars$cvec, Amat=mip_pars$Amat, Qmat = mip_pars$Qmat,
               bvec=mip_pars$bvec, sense = mip_pars$sense,
               lb=mip_pars$lb, ub=mip_pars$ub,
               vtype = mip_pars$vtype, objsense = "max", control=list(trace=0))
  mip_out = recover_pars(sol, n_train, n_test-1, p)
  mip_outputs[[i]] = mip_out
  yest = mean(y_test[-i][which(mip_out$w>=0.1)])
  simdata[i, ] = c(xi, mip_out$a, mip_out$b, y_test[i], yest)
}
print(paste("100 matches took", round(proc.time()[3] - t1, 1)))
```

```{r "simple MIP-P p=2 plot"}
ggplot(simdata) + 
  geom_rect(aes(xmin=a1, ymin=a2, xmax=b1, ymax=b2), fill="grey", 
            color="black", size=0.5, alpha=0.3) + 
  geom_point(aes(x=x1, y=x2, color=abs(yest - y)/mean(abs(y))), size=2) + 
  scale_color_gradient(low="blue", high="red") + 
  xlab("x1") + ylab("x2") +  labs(color="% Abs. error") +  theme_bw() + 
  theme(legend.position = c(0.9,0.5), 
        legend.background = element_rect(color="black", size=0.5))
#ggsave("01-21_p=2_plot.png")
```


# Simulation 1

\begin{align*}
p = 2\\
x_{ij} &\sim Uniform(-3, 3)\\
e_i &= logit(\mathbf{x}_i^T\beta)\\
z_i &\sim Bernoulli(e_i)\\
\epsilon_i &\sim Normal(0, 1)\\
Y_i &= \alpha + z_i \mathbb{I}_{x_{i1} > 0.5}5 + \epsilon_i.
\end{align*}

```{r "sim 1", cache=T}
x_dgp = function(n, p){
  return(matrix(rexp(n*p, 2), n, p))
}
res = matching_sim(10, 200, 3, lambda=4, alpha=-1, beta=0, gamma=0, lambda0=1, lambda1=1, 
                   gamma0=2, gamma1=2, X_dgp=x_dgp, m = 2,
                   estimators = c("MIQP-Fhat", "Greedy", "CEM", "Full Matching" , 
                                  "Nearest Neighbor", "Prognostic", "Mahalanobis"))
res$estimator = factor(res$estimator, levels=c("MIQP-Fhat", "Greedy", "CEM", "Full Matching" , 
                                               "Nearest Neighbor", "Prognostic", "Mahalanobis"))
```

```{r "sim 1 plot"}
CATE_error_plot(res)
```


# Simulation 2

\begin{align*}
p = 10\\
x_{ij} &\sim Uniform(-3, 3)\\
e_i &= logit(\mathbf{x}_i^T\beta)\\
z_i &\sim Bernoulli(e_i)\\
\epsilon_i &\sim Normal(0, 1)\\
Y_i &= \alpha + z_i \mathbb{I}_{x_{i1} > 0.5}5 + \epsilon_i.
\end{align*}

```{r "sim 2", cache=T}
res = matching_sim(10, 200, 10)
res$estimator = factor(res$estimator, levels=c("MIP-Explain", "MIP-Predict", "MIQP-Variance", "Greedy", "CEM", "Full Matching" , "Nearest Neighbor", "Prognostic", "Mahalanobis"))
```

```{r "sim 2 plot"}
CATE_error_plot(res)
```


# Simulation Vittorio
```{r}
X_dgp = function(n, p){
  matrix(runif(n * p, min = 0, max = 5), n, p)
}
y_dgp <- function(x, z, eps, n_irrelevant = 8) {
  p <- ncol(x) - n_irrelevant

  # beta <- rnorm(p, 1.5, 0.15 ^ 0.5)
  beta_tilde <- 5
  Y <- 
    beta_tilde * z + eps
  
  # Y <- rowSums(sweep(x, 2, alpha, '*')) + z * rowSums(sweep(x, 2, beta, '*')) +  
  #   z * (x[, 1] * x[, 2] + x[, 1] * x[, 3] + x[, 2] * x[, 3]) + eps
  return(Y)
}
res <- matching_sim(10, 200, 5, X_dgp = X_dgp, y_dgp = y_dgp,
                   estimators =  c('MIQP-Fhat', 'Greedy', 'Nearest Neighbor', 'CEM', 'Full Matching', 'Prognostic', 'Mahalanobis'))
res$estimator %<>% factor(levels = c('Greedy', 'Nearest Neighbor', 'CEM', 'Full Matching', 'Prognostic', 'Mahalanobis'))
CATE_error_plot(res)
```


# Simulation 3

\begin{align*}
p = 3\\
x_{ij} &\sim exponential(0.5)\\
e_i &= logit(\mathbf{x}_i^T\beta)\\
z_i &\sim Bernoulli(e_i)\\
\epsilon_i &\sim Normal(0, 1)\\
Y_i &= \alpha + z_i \mathbb{I}_{x_{i1} > 0.5}5 + \epsilon_i.
\end{align*}

```{r "sim 3", cache=T}
X_dgp = function(n, p){
  matrix(runif(n * p, min = 0, max = 5), n, p)
}
y_dgp <- function(x, z, eps) {
  p <- ncol(x) - 3 # 3 irrelevant covariates
  alpha <- rnorm(p, 10 * sample(c(-1, 1), 1), 1)
  beta <- rnorm(p, 1.5, 0.15 ^ 0.5)
  Y <- rowSums(sweep(x, 2, alpha, '*')) + z * rowSums(sweep(x, 2, beta, '*')) +  
    z * (x[, 1] * x[, 2] + x[, 1] * x[, 3] + x[, 2] * x[, 3]) + eps
  return(Y)
}
res = matching_sim(10, 200, 6, X_dgp = X_dgp, y_dgp = y_dgp,
                   estimators =  c('MIQP-Fhat', 'Greedy', 'Nearest Neighbor', 'CEM', 'Full Matching', 'Prognostic', 'Mahalanobis'))
res$estimator %<>% factor(levels = c('MIQP-Fhat', 'Greedy', 'Nearest Neighbor', 'CEM', 'Full Matching', 'Prognostic', 'Mahalanobis'))
CATE_error_plot(res)
```



# Simulation 4

\begin{align*}
p = 3\\
x_{ij} &\sim uniform(0.5)\\
e_i &= logit(\mathbf{x}_i^T\beta)\\
z_i &\sim Bernoulli(e_i)\\
\epsilon_i &\sim Normal(0, 1)\\
\mathbf{B} &= diag([0, 2, 1])\\
Y_i &= 2 + 5z_i + z_i\mathbf{x}^T\mathbf{B}\mathbf{x} + \epsilon_i.
\end{align*}

```{r "sim 4", cache=T}
y_dgp = function(X, Z, eps){
  B = diag(c(0, 2, 1))
  HTE = (Z * apply(X, 1, function(x) x %*% B %*% x))
  return(2 + 5 * Z + HTE + eps)
}
x_dgp = function(n, p){
  return(matrix(runif(n*p, 0, 1), n, p))
}
# res = matching_sim(10, 200, 3, y_dgp=y_dgp,lambda=4, alpha=2, beta=0, gamma=0, m=2)
# res$estimator = factor(res$estimator, levels=c("MIP-Explain", "MIP-Predict", "MIQP-Variance", 
#                                                "Greedy", "CEM", "Full Matching" , "Nearest Neighbor", 
#                                                "Prognostic", "Mahalanobis"))
res = matching_sim(10, 200, 3, lambda=4, alpha=-2, beta=0, gamma=0, y_dgp = y_dgp, X_dgp = x_dgp,
                   lambda0=1, lambda1=1, gamma1=2, gamma0=2, m=2,
                   estimators = c("MIQP-Fhat", "Greedy", "CEM", "Full Matching" , 
                                  "Nearest Neighbor", "Prognostic", "Mahalanobis"))
res$estimator = factor(res$estimator, levels=c("MIQP-Fhat", "Greedy", "CEM", "Full Matching" , 
                                               "Nearest Neighbor", "Prognostic", "Mahalanobis"))
```

```{r "sim 4 plot"}
CATE_error_plot(res)
```


# Simulation 5

\begin{align*}
p = 10\\
x_{ij} &\sim uniform(0.5)\\
e_i &= logit(\mathbf{x}_i^T\beta)\\
z_i &\sim Bernoulli(e_i)\\
\epsilon_i &\sim Normal(0, 1)\\
\mathbf{B} &= diag([0, 2, 1, 0, 0, 1, 1, 2, 3, 0])\\
Y_i &= 2 + 5z_i + z_i\mathbf{x}_i^T\mathbf{B}\mathbf{x}_i + \epsilon_i.
\end{align*}

```{r "sim 5", cache=T}
HTE_dgp = function(X, Z){
  B = diag(c(0, 2, 1, 0, 0, 1, 1, 2, 3, 0))
  return(Z * apply(X, 1, function(x) x %*% B %*% x))
}
y_dgp = function(X, Z, HTE){
  return(2 + 5 * Z + HTE + rnorm(nrow(X), 0, 1))
}
res = matching_sim(10, 200, 10, HTE_dgp = HTE_dgp, y_dgp=y_dgp)
res$estimator = factor(res$estimator, levels=c("MIP-Explain", "MIP-Predict", "MIQP-Variance", 
                                               "Greedy", "CEM", "Full Matching" , "Nearest Neighbor", 
                                               "Prognostic", "Mahalanobis"))
```

```{r "sim 5 plot"}
CATE_error_plot(res)
```


# Simulation 6

\begin{align*}
p = 3\\
x_{ij} &\sim uniform(0.5)\\
e_i &= logit(\mathbf{x}_i^T\beta)\\
z_i &\sim Bernoulli(e_i)\\
\epsilon_i &\sim Normal(0, 1)\\
\mathbf{B} &= diag([0, 2, 1])\\
Y_i &= 2 + 5z_i + z_i\mathbf{x}_i^T\mathbf{B}\mathbf{x}_i + \mathbf{x}_i^t\gamma + \epsilon_i.
\end{align*}

```{r "sim 6", cache=T}
y_dgp = function(X, Z, eps){
  gamma = c(2,0,1)
  B = diag(c(0,2,1))
  return(2 + 5 * Z + Z * apply(X, 1, function(x) x %*% B %*% x) + as.matrix(X) %*% gamma + eps)
}
res = matching_sim(10, 200, 3, y_dgp=y_dgp)
res$estimator = factor(res$estimator, levels=c("MIP-Explain", "MIP-Predict", "MIQP-Variance", 
                                               "Greedy", "CEM", "Full Matching" , "Nearest Neighbor", 
                                               "Prognostic", "Mahalanobis"))
```

```{r "sim 6  plot"}
CATE_error_plot(res)
```



# Simulation 7

\begin{align*}
p = 5\\
x_{ij} &\sim uniform(0.5)\\
e_i &= logit(\mathbf{x}_i^T\beta)\\
z_i &\sim Bernoulli(e_i)\\
\epsilon_i &\sim Normal(0, 1)\\
\mathbf{B} &= diag([0, 2, 1])\\
Y_i &= 2 + 5z_i + z_i\mathbf{x}_i^T\mathbf{B}\mathbf{x}_i + \mathbf{x}_i^t\gamma + \epsilon_i.
\end{align*}

```{r "sim 7", cache=T}
x_dgp = function(n, p){
  return(matrix(runif(n*p, 0, 1), n, p))
}
y_dgp = function(X, Z, eps){
  HTE = 10 * sin(pi * X[, 1]*X[, 2]) + 20 * (X[, 3] - 0.5)^2 + 10 * X[, 4] + 5 * X[, 5]
  return (2 + HTE + Z*5 + eps)
}
res = matching_sim(10, 200, 5, lambda=4, alpha=-2, beta=0, gamma=0, y_dgp = y_dgp, X_dgp = x_dgp,
                   lambda0=1, lambda1=1, gamma1=2, gamma0=2, m=2,
                   estimators = c("MIQP-Fhat", "Greedy", "CEM", "Full Matching" , 
                                  "Nearest Neighbor", "Prognostic", "Mahalanobis"))
res$estimator = factor(res$estimator, levels=c("MIQP-Fhat","Greedy", "CEM", "Full Matching" , "Nearest Neighbor", 
                                               "Prognostic", "Mahalanobis"))
```

```{r "sim 7  plot"}
CATE_error_plot(res)
```


# Hyperparam Comparisons

```{r "hp comparison", cache=TRUE}
lambdas = 1:5
alphas = -5:5
simdata = NULL
for(lambda in lambdas){
  for (alpha in alphas){
    res = matching_sim(5 , 100, p=3, alpha=alpha, lambda=lambda)
    res = summarize_CATEs(res)
    simdata = rbind(simdata, data.frame(res, lambda=rep(lambda, nrow(res)), alpha=rep(alpha, nrow(res))))
  }
}
```

```{r "hp plot"}
ggdata =simdata[simdata$estimator %in% c("MIP-Explain", "MIP-Predict", "MIQP-Variance"), ]
ggplot(ggdata) + geom_point(aes(x=alpha, y=MSE, color=estimator)) + facet_grid(lambda~.)
```


# MG Analysis

## DGP 1

```{r "MG analysis", cache=TRUE}
c(df, HTE_true) %<-% simulate_data(200, 3)
c(df, f, n, n_train, p,
    train_df, train_covs, train_control, train_treated,
    test_df, test_covs, test_control, test_treated, 
    n_test_control, n_test_treated, 
    bart_fit, counterfactuals) %<-% estimator_inputs(df, 100, 200)
c(greedy_cates, greedy_bins) %<-% est_greedy(train_df, test_df, test_covs, test_control, test_treated,
                                             n_test_treated, 3, bart_fit)
c(miqp_cates, miqp_bins) %<-% est_MIQP_fhat(test_df, test_treated, n_test_treated, test_covs, bart_fit, 
                                            n_train, p, lambda=3, alpha=0, m=2)

miqp_cates2 = rep(NA, n_test_treated)
for (i in 1:n_test_treated){
  mg = make_mg(test_covs, miqp_bins[i,,1], miqp_bins[i,,2])
  miqp_cates2[i] = mean(test_df$Y[mg][test_df$treated[mg]]) - mean(test_df$Y[mg][!test_df$treated[mg]])
}

HTE_tt = HTE_true[test_treated]

ge = abs(HTE_tt - greedy_cates)
me = abs(HTE_tt - miqp_cates)
me2 = abs(miqp_cates2 - HTE_tt)

mip_pars =  setup_miqp_variance(xi = as.numeric(test_covs[i, ]),
                                    y_train = train_df$Y,
                                    x_train = train_covs,
                                    z_train = train_df$treated,
                                    x_test = as.matrix(test_covs[test_df$treated==0, ]),  
                                    alpha=alpha, lambda=lambda, m=m, M=M)
sol <- do.call(Rcplex, c(mip_pars, list(objsense="max", control=list(trace=0))))
mip_out = recover_pars(sol, nrow(train_df), sum(test_df$treated==0), p)
    
```


## DGP 2
```{r "MG analysis", cache=TRUE}
p=2
y_dgp = function(X, Z, eps){
  ind = (X[, 1] > 0.5  & X[, 2] > 0.5)
  return(1 + Z * 5 + ind * 3 + eps)
}
x_dgp = function(n, p){
  return(matrix(runif(n*p, 0, 1), n, p))
}
e_dgp = function(X){
  ind = (X[, 1] > 0.5  & X[, 2] > 0.5)
  return(ind * 0.5)
}
c(df, HTE) %<-% simulate_data(200, 3, y_dgp = y_dgp, X_dgp=x_dgp)
c(df, f, n, n_train, p,
    train_df, train_covs, train_control, train_treated,
    test_df, test_covs, test_control, test_treated, 
    n_test_control, n_test_treated, 
    bart_fit, counterfactuals) %<-% estimator_inputs(df, 100, 200)
HTE_test_treated = HTE[test_treated]
c(greedy_cates, greedy_bins) %<-% est_greedy(train_df, test_df, test_covs, test_control, test_treated,
                                             n_test_treated, 3, bart_fit)
c(miqp_cates, miqp_bins) %<-% est_MIQP_fhat(test_df, test_treated, n_test_treated, test_covs, bart_fit, 
                                            n_train, p, 
                                            lambda0=1, lambda1=1, gamma0=0.5, gamma1=0.5,
                                            alpha=-1, beta=2, m=1)

miqp_mq = rep(NA, n_test_treated)
greedy_mq = rep(NA, n_test_treated)
for (i in 1:n_test_treated){
  mg = make_mg(test_covs, miqp_bins[i,,1], miqp_bins[i,,2])
  miqp_mq[i] = mean(abs(colMeans(test_covs[mg, ][test_df$treated[mg],]) - 
                          colMeans(test_covs[mg, ][!test_df$treated[mg],])))
  mg = make_mg(test_covs, greedy_bins[i,,1], greedy_bins[i,,2])
  greedy_mq[i] = mean(abs(colMeans(test_covs[mg, ][test_df$treated[mg],]) - 
                          colMeans(test_covs[mg, ][!test_df$treated[mg],])))
}

ge = abs(HTE_test_treated - greedy_cates)
me = abs(HTE_test_treated - miqp_cates)

print(mean(me))

mip_pars =  setup_miqp_variance(xi = as.numeric(test_covs[i, ]),
                                    y_train = train_df$Y,
                                    x_train = train_covs,
                                    z_train = train_df$treated,
                                    x_test = as.matrix(test_covs[test_df$treated==0, ]),  
                                    alpha=alpha, lambda=lambda, m=m, M=M)
sol <- do.call(Rcplex, c(mip_pars, list(objsense="max", control=list(trace=0))))
mip_out = recover_pars(sol, nrow(train_df), sum(test_df$treated==0), p)
    
```


## Bins

```{r "Bins"}
p=2
y_dgp = function(X, Z, eps){
  ind = (X[, 1] > 0.5  & X[, 2] > 0.5)
  return(1 + Z * 5 + ind * 3 + eps)
}
x_dgp = function(n, p){
  return(matrix(runif(n*p, 0, 1), n, p))
}
c(df, HTE) %<-% simulate_data(200, 3, y_dgp = y_dgp, X_dgp=x_dgp)
c(df, f, n, n_train, p,
    train_df, train_covs, train_control, train_treated,
    test_df, test_covs, test_control, test_treated, 
    n_test_control, n_test_treated, 
    bart_fit, counterfactuals) %<-% estimator_inputs(df, 100, 200)
HTE_test_treated = HTE[test_treated]
mip_out <- est_MIQP_fhat(test_df, test_treated, n_test_treated, test_covs, bart_fit, 
                                            n_train, p, 
                                            lambda0=1, lambda1=1, gamma0=0.5, gamma1=0.5,
                                            alpha=-1, beta=2, m=1)
c(miqp_cates, miqp_bins) %<-% mip_out

me = abs(HTE_test_treated - miqp_cates)
print(mean(me))

bin_plot(mip_out, test_df, 1, 2, 0.5, 1, 0.5, 1)
```



```{r "Bins2"}
p=2
y_dgp = function(X, Z, eps){
  ind = (X[, 1] > 0.1 & X[, 1] < 0.6 & X[, 2] > 0.4 & X[, 2] < 0.8)
  return(1 + Z * 5 + ind * 5 + eps)
}
x_dgp = function(n, p){
  return(matrix(runif(n*p, 0, 1), n, p))
}
c(df, HTE) %<-% simulate_data(200, p, y_dgp = y_dgp, X_dgp=x_dgp)
c(df, f, n, n_train, p,
    train_df, train_covs, train_control, train_treated,
    test_df, test_covs, test_control, test_treated, 
    n_test_control, n_test_treated, 
    bart_fit, counterfactuals) %<-% estimator_inputs(df, 100, 200)
HTE_test_treated = HTE[test_treated]
mip_out <- est_MIQP_fhat(test_df, test_treated, n_test_treated, test_covs, bart_fit, 
                                            n_train, p, 
                                            lambda0=1, lambda1=1, gamma0=1, gamma1=1,
                                            alpha=0, beta=3, m=1)
c(miqp_cates, miqp_bins) %<-% mip_out

me = abs(HTE_test_treated - miqp_cates)
print(mean(me))

fhat1 = predict(bart_fit, newdata = as.matrix(cbind(test_covs, treated=1)))
fhat0 = predict(bart_fit, newdata = as.matrix(cbind(test_covs, treated=0)))
bcates = fhat1[test_treated] - fhat0[test_treated]
be = mean(abs(HTE_test_treated - bcates))
print(be)

bin_plot(miqp_bins, test_df, 1, 2, 0.1, 0.6, 0.4, 0.8)
```


## True F

```{r "Bins2"}
generate_grid = function(xi, test_covs, d){
  n = nrow(test_covs)
  p = ncol(test_covs)
  grid = NULL
  for (k in 1:n){
    xk = test_covs[k, ]
    means = (xi + xk)/2
    for(j in 1:p){
      grdj = seq(min(xi[j], xk[j]), max(xi[j], xk[j]), length.out = d)
      xgrdj = matrix(rep(means, d), d, p, byrow=T)
      xgrdj[, j] = grdj
      grid = rbind(grid, xgrdj)
    }
  }
  return(grid)
}


p=2
y_dgp = function(X, Z, eps){
  ind = (X[, 1] > 0.1 & X[, 1] < 0.6 & X[, 2] > 0.4 & X[, 2] < 0.8)
  return(1 + Z * 5 + ind * 5 + eps)
}
x_dgp = function(n, p){
  return(matrix(runif(n*p, 0, 1), n, p))
}
c(df, HTE) %<-% simulate_data(200, p, y_dgp = y_dgp, X_dgp=x_dgp)
c(df, f, n, n_train, p,
    train_df, train_covs, train_control, train_treated,
    test_df, test_covs, test_control, test_treated, 
    n_test_control, n_test_treated, 
    bart_fit, counterfactuals) %<-% estimator_inputs(df, 100, 200)
HTE_test_treated = HTE[test_treated]

alpha=0
lambda0=1
lambda1=1
gamma0=2
gamma1=2
beta=2
m=1
M=1e5
mip_cates = vector('numeric', n_test_treated)
mip_bins = array(NA, c(n_test_treated, p, 2))
# fhat1 = predict(bart_fit, newx=as.matrix(cbind(test_covs, treated=1)))
# fhat1 = fhat1[ ,ncol(fhat1)]
# fhat0 = predict(bart_fit, newx=as.matrix(cbind(test_covs, treated=0)))
# fhat0 = fhat0[, ncol(fhat0)]
# fhat1 = predict(bart_fit, newdata=as.matrix(cbind(test_covs, treated=1)))
# fhat0 = predict(bart_fit, newdata=as.matrix(cbind(test_covs, treated=0)))
ftrue1 = y_dgp(test_covs, 1, 0)
ftrue0 = y_dgp(test_covs, 0, 0)
message("Running MIQP-Fhat")
for (l in 1:n_test_treated){
  i = test_treated[l]
  message(paste("Matching unit", l, "of", n_test_treated), "\r", appendLF = FALSE); flush.console()
  
  mip_pars =  setup_miqp_fhat(xi = as.numeric(test_covs[i, ]),
                              x_test = as.matrix(test_covs[-i, ]),
                              z_test = test_df$treated[-i],
                              fhati1=ftrue1[i],
                              fhati0=ftrue0[i],
                              fhat1=ftrue1[-i],
                              fhat0=ftrue0[-i], 
                              alpha=alpha, lambda0=lambda0, lambda1=lambda1,
                              gamma0=gamma0, gamma1=gamma1, beta=beta, m=m, M=M)
  sol <- do.call(Rcplex, c(mip_pars, list(objsense="max", control=list(trace=0))))
  mip_out = recover_pars(sol, n_train, nrow(test_covs), p)
  
  mip_bins[l, ,1] = mip_out$a
  mip_bins[l, ,2] = mip_out$b
  #mip_cates[l] = test_df$Y[i] - mean(test_df$Y[test_df$treated==0][mip_out$w>=0.1])

  mg = make_mg(test_covs, mip_out$a, mip_out$b)
  #mip_cates[l] = mean(test_df$Y[mg][test_df$treated[mg]]) - mean(test_df$Y[mg][!test_df$treated[mg]])
  mip_cates[l] = test_df$Y[i] - mean(test_df$Y[mg][!test_df$treated[mg]])
}
message("\n")


me = abs(HTE_test_treated - mip_cates)
print(mean(me))

fhat1 = predict(bart_fit, newdata = as.matrix(cbind(test_covs, treated=1)))
fhat0 = predict(bart_fit, newdata = as.matrix(cbind(test_covs, treated=0)))
bcates = fhat1[test_treated] - fhat0[test_treated]
be = mean(abs(HTE_test_treated - bcates))
print(be)

bin_plot(mip_bins, test_df, 1, 2, 0.1, 0.6, 0.4, 0.8)

```


## Grid

```{r "Bins2"}
# generate_grid = function(xi, test_covs, d){
#   n = nrow(test_covs)
#   p = ncol(test_covs)
#   grid = NULL
#   for (k in 1:n){
#     xk = test_covs[k, ]
#     means = (xi + xk)/2
#     for(j in 1:p){
#       grdj = seq(min(xi[j], xk[j]), max(xi[j], xk[j]), length.out = d)
#       xgrdj = matrix(rep(means, d), d, p, byrow=T)
#       xgrdj[, j] = grdj
#       grid = rbind(grid, xgrdj)
#     }
#   }
#   # The grid is mysteriously a list because R is a very good language 
#   grid = (apply(grid,2, unlist))
#   colnames(grid) = colnames(test_covs)
#   return(grid)
# }


p=2
y_dgp = function(X, Z, eps){
  ind = (X[, 1] > 0.1 & X[, 1] < 0.6 & X[, 2] > 0.4 & X[, 2] < 0.8)
  return(1 + Z * 5 + ind * 5 + eps)
}
x_dgp = function(n, p){
  return(matrix(runif(n*p, 0, 1), n, p))
}
c(df, HTE) %<-% simulate_data(200, p, y_dgp = y_dgp, X_dgp=x_dgp)
c(df, f, n, n_train, p,
    train_df, train_covs, train_control, train_treated,
    test_df, test_covs, test_control, test_treated, 
    n_test_control, n_test_treated, 
    bart_fit, counterfactuals) %<-% estimator_inputs(df, 100, 200, black_box = 'xgb')
HTE_test_treated = HTE[test_treated]

alpha=0
lambda0=0
lambda1=0
gamma0=2
gamma1=2
beta=2
m=1
M=1e5
mip_cates = vector('numeric', n_test_treated)
mip_bins = array(NA, c(n_test_treated, p, 2))
# fhat1 = predict(bart_fit, newx=as.matrix(cbind(test_covs, treated=1)))
# fhat1 = fhat1[ ,ncol(fhat1)]
# fhat0 = predict(bart_fit, newx=as.matrix(cbind(test_covs, treated=0)))
# fhat0 = fhat0[, ncol(fhat0)]
message("Running MIQP-Fhat")
for (l in 1:n_test_treated){
  i = test_treated[l]
  message(paste("Matching unit", l, "of", n_test_treated), "\r", appendLF = FALSE); flush.console()
  
  grid = generate_grid(test_covs[i, ], test_covs[-i, ], 3)
  fhat1 = predict(bart_fit, newdata=as.matrix(cbind(grid, treated=1)))
  fhat0 = predict(bart_fit, newdata=as.matrix(cbind(grid, treated=0)))
  fhati1 = predict(bart_fit, newdata=as.matrix(cbind(test_covs, treated=1)))[i]
  fhati0 = predict(bart_fit, newdata=as.matrix(cbind(test_covs, treated=0)))[i]
  mip_pars =  setup_miqp_fhat(xi = as.numeric(test_covs[i, ]),
                              x_test = grid,
                              z_test = rep(1, nrow(grid)),
                              fhati1=fhati1,
                              fhati0=fhati0,
                              fhat1=fhat1,
                              fhat0=fhat0, 
                              alpha=alpha, lambda0=lambda0, lambda1=lambda1,
                              gamma0=gamma0, gamma1=gamma1, beta=beta, m=m, M=M)
  sol <- do.call(Rcplex, c(mip_pars, list(objsense="max", control=list(trace=0))))
  mip_out = recover_pars(sol, n_train, nrow(test_covs), p)
  
  mip_bins[l, ,1] = mip_out$a
  mip_bins[l, ,2] = mip_out$b
  #mip_cates[l] = test_df$Y[i] - mean(test_df$Y[test_df$treated==0][mip_out$w>=0.1])

  mg = make_mg(test_covs, mip_out$a, mip_out$b)
  #mip_cates[l] = mean(test_df$Y[mg][test_df$treated[mg]]) - mean(test_df$Y[mg][!test_df$treated[mg]])
  mip_cates[l] = test_df$Y[i] - mean(test_df$Y[mg][!test_df$treated[mg]])
}
message("\n")


me = abs(HTE_test_treated - mip_cates)
print(mean(me))

fhat1 = predict(bart_fit, newdata = as.matrix(cbind(test_covs, treated=1)))
fhat0 = predict(bart_fit, newdata = as.matrix(cbind(test_covs, treated=0)))
bcates = fhat1[test_treated] - fhat0[test_treated]
be = mean(abs(HTE_test_treated - bcates))
print(be)

bin_plot(mip_bins, test_df, 1, 2, 0.1, 0.6, 0.4, 0.8)

```

## More debugging

```{r}
generate_grid = function(xi, test_covs, d){
  n = nrow(test_covs)
  p = ncol(test_covs)
  grid = NULL
  for (k in 1:n){
    xk = test_covs[k, ]
    means = (xi + xk)/2
    for(j in 1:p){
      grdj = seq(min(xi[j], xk[j]), max(xi[j], xk[j]), length.out = d)
      xgrdj = matrix(rep(means, d), d, p, byrow=T)
      xgrdj[, j] = grdj
      grid = rbind(grid, xgrdj)
    }
  }
  # The grid is mysteriously now a list because R is a very good language 
  grid = (apply(grid,2, unlist))
  colnames(grid) = colnames(test_covs)
  return(grid)
}

y_dgp_quadratic <- function(x, z, eps) {
  beta_tilde <- 2
  gamma_tilde <- 1
  Y <-
    beta_tilde * rowSums(x^2) * z +
    gamma_tilde * rowSums(x^2) + eps
  return(Y)
}

y_dgp_linear_irr <- function(x, z, eps) {
  beta_tilde <- 3
  gamma_tilde <- 2
  Y <- 
    beta_tilde * (x[, 1] - 0) * z +
    gamma_tilde * (x[, 1] - 0) + eps
  return(Y)
}

y_dgp_constant_irr <- function(x, z, eps) {
  beta_tilde <- 3
  gamma_tilde <- 2
  Y <- 
    beta_tilde * z +
    gamma_tilde * (x[, 1] - 0) + eps
  return(Y)
}

y_dgp_simple <- function(x, z, eps) {
  beta_tilde <- 3
  gamma_tilde <- 2
  Y <- beta_tilde * z + eps
  return(Y)
}

y_dgp_box = function(X, Z, eps){
  ind = (X[, 1] > 0.5  & X[, 2] > 0.5)
  return(1 + Z * 5 + ind * 3 + eps)
}

y_dgp_bart = function(X, Z, eps){
  Y<- 10 * sin(pi * X[, 1]*X[, 2]) + 20 *(X[, 3] - 0.5)^2 + 10*X[, 4] + 5*X[, 5] + 5 * X[, 3] * Z + eps
  return(Y)
}

x_dgp = function(n, p){
  return(matrix(runif(n*p, 0, 1), n, p))
}
########################################################
# Simulations
########################################################
all_y_dgp <- list(y_dgp_linear_irr,
                  y_dgp_quadratic,
                  y_dgp_bart)
all_p_vals <- list(2, 2, 5) # Need as many ps as dgps

sim_types <- c('Linear', 
               'Quadratic',
               'Bart Function')


n_dgp <- length(all_y_dgp)
nsims = 5
n = 400
n_train = 300
alpha=0
lambda0=0
lambda1=0
gamma0=2
gamma1=2
beta=3
m=1
M=1e5
all_dgp_CATEs <- vector('list', length = n_dgp)
for (dgp in 1:n_dgp) {
  y_dgp <- all_y_dgp[[dgp]]
  p = all_p_vals[[dgp]]

  all_CATEs = NULL
  message(paste('Starting', sim_types[dgp], 'DGP', sep = ' '))
  for (sim in 1:nsims) {
    c(df, HTE) %<-% simulate_data(n, p, y_dgp = y_dgp, X_dgp=x_dgp)
    inputs <- estimator_inputs(df, n_train, n, 'BART', cv = FALSE)
    c(df, f, n, n_train, p,
        train_df, train_covs, train_control, train_treated,
        test_df, test_covs, test_control, test_treated, 
        n_test_control, n_test_treated, 
        bart_fit, counterfactuals) %<-% inputs
    HTE_test_treated = HTE[(n_train+1):n][test_df$treated]
    
    # Matching methods

    m_estimators <- c('Full Matching', 'Prognostic', 'CEM', 'GenMatch',
                      'Mahalanobis', 'Nearest Neighbor', 'Greedy')
    est_out <- suppressWarnings(get_CATEs(inputs, m_estimators, hyperparameters = list(0, 0, 0, 0, 0, 0, 0, 0, 0, 0)))

    CATEs = est_out$CATEs
    
    ## best match on true expected CF
    ftrue0 = y_dgp(test_covs, rep(0, n - n_train), rep(0, n - n_train))
    CATEs = cbind(CATEs, est_prog(test_df, ftrue0[test_treated]))
    # message(paste("Mean best CF error", mean(abs(CATEs[, 6] - HTE_test_treated))))
    
    ## BART
    fhat1 = colMeans(predict(bart_fit, test = as.matrix(cbind(test_covs, treated=1))))
    fhat0 = colMeans(predict(bart_fit, test = as.matrix(cbind(test_covs, treated=0))))
    bcates = (fhat1 - fhat0)
    CATEs = cbind(CATEs, bcates[test_treated])
    # message(paste("Mean BART error", mean(abs(CATEs[, 7] - HTE_test_treated))))
    
    ## BART overfit v1
    ofcates = rep(NA, n_test_treated)
    for (l in 1:n_test_treated){
      i = test_treated[l]
      match0 = which.min(abs(fhat0[i] - test_df$Y[test_control]))
      match1 = which.min(abs(fhat1[i] - test_df$Y[test_treated]))
      ofcates[l] = test_df$Y[test_treated][match1] - test_df$Y[test_control][match0]
    }
    CATEs = cbind(CATEs, ofcates)
    
    ## BART overfit v2
    ofcates2 = rep(NA, n_test_treated)
    for (l in 1:n_test_treated){
      i = test_treated[l]
      match0 = which.min(abs(fhat0[i] - fhat0[test_control]))
      match1 = which.min(abs(fhat1[i] - fhat1[test_treated]))
      ofcates2[l] = test_df$Y[test_treated][match1] - test_df$Y[test_control][match0]
    }
    CATEs = cbind(CATEs, ofcates2)
    
    ## MIP
    mip_cates = vector('numeric', n_test_treated)
    mip_cates_both = vector('numeric', n_test_treated)
    mip_bins = array(NA, c(n_test_treated, p, 2))
    message("Running MIQP-Fhat")
    for (l in 1:n_test_treated){
      i = test_treated[l]
      message(paste("Matching unit", l, "of", n_test_treated), "\r", appendLF = FALSE); flush.console()
      
      mip_pars =  setup_miqp_fhat(xi = as.numeric(test_covs[i, ]),
                                  x_test = as.matrix(test_covs[-i, ]),
                                  z_test = test_df$treated[-i],
                                  fhati1=fhat1[i],
                                  fhati0=fhat0[i],
                                  fhat1=fhat1[-i],
                                  fhat0=fhat0[-i], 
                                  alpha=alpha, lambda0=lambda0, lambda1=lambda1,
                                  gamma0=gamma0/sd(fhat0), gamma1=gamma1/sd(fhat1), 
                                  beta=beta, m=m, M=M)
      sol <- do.call(Rcplex, c(mip_pars, list(objsense="max", control=list(trace=0))))
      mip_out = recover_pars(sol, n_train, nrow(test_covs), p)
    
      mip_bins[l, ,1] = mip_out$a
      mip_bins[l, ,2] = mip_out$b
  
      mg = make_mg(test_covs, mip_out$a, mip_out$b)
      mip_cates[l] = test_df$Y[i] - mean(test_df$Y[mg][!test_df$treated[mg]])
      mip_cates_both[l] = mean(test_df$Y[mg][test_df$treated[mg]]) - mean(test_df$Y[mg][!test_df$treated[mg]])
    }
    message("")
    CATEs <- cbind(CATEs, mip_cates)
    CATEs <- cbind(CATEs, mip_cates_both)
    # message(paste("Mean MIP error", mean(abs(CATEs[, 8] - HTE_test_treated), na.rm=T)))
    
    fcates = format_CATEs(CATEs, true_CATE = HTE_test_treated,
                        estimators = c('Full Matching', 'Prognostic', 'CEM', 'GenMatch',
                                       'Mahalanobis', 'Nearest Neighbor', 'Greedy',
                                       'Best CF', 'BART', 'BART of 1', 'BART of 2',  'MIP', 'MIP_both'))
    all_CATEs <- rbind(all_CATEs, fcates)
    message(sprintf('%d of %d simulations completed', sim, nsims))
  }
  all_dgp_CATEs[[dgp]] <- all_CATEs
}
#saveRDS(all_dgp_CATEs, 'sims_2-12_part2.rds')
# CATE_error_plot(all_CATEs)
# print(summarize_CATEs(all_CATEs))
#bin_plot(mip_bins, test_df, 1, 2)
```

```{r}
saveRDS(all_BART_CATEs, 'sim_BART.rds')
saveRDS(all_box_CATEs, 'sim_box.rds')
saveRDS(all_const_conf_CATEs, 'sim_constant_conf.rds')
saveRDS(all_linear_CATEs, 'sim_linear.rds')
saveRDS(all_quad_CATEs, 'sim_quadratic.rds')
saveRDS(all_simple_CATEs, 'sim_constant.rds')
```

```{r}
require(cowplot)
bart_sim_plot <- CATE_error_plot(all_BART_CATEs)
ggsave(paste('new_sim_BART.png'),
       width = 10, height = 8, units = 'in', device = 'png', dpi = 300)
box_sim_plot <- CATE_error_plot(all_box_CATEs)
ggsave(paste('new_sim_box.png'),
       width = 10, height = 8, units = 'in', device = 'png', dpi = 300)
const_conf_sim_plot <- CATE_error_plot(all_const_conf_CATEs)
ggsave(paste('new_sim_constant_conf.png'),
       width = 10, height = 8, units = 'in', device = 'png', dpi = 300)
linear_sim_plot <- CATE_error_plot(all_linear_CATEs)
ggsave(paste('new_sim_linear.png'),
       width = 10, height = 8, units = 'in', device = 'png', dpi = 300)
quad_sim_plot <- CATE_error_plot(all_quad_CATEs)
ggsave(paste('new_sim_quad.png'),
       width = 10, height = 8, units = 'in', device = 'png', dpi = 300)
simple_sim_plot <- CATE_error_plot(all_simple_CATEs)
ggsave(paste('new_sim_simple.png'),
       width = 10, height = 8, units = 'in', device = 'png', dpi = 300)

plot_grid(simple_sim_plot, const_conf_sim_plot, box_sim_plot,
          linear_sim_plot, quad_sim_plot, bart_sim_plot,
          labels = c('Constant', 'Constant w/Confounding', 'Box',
                     'Linear', 'Quadratic', 'BART Function'))
ggsave('all_new_sims.png',
       width = 12, height = 10, units = 'in', device = 'png', dpi = 300)
```






