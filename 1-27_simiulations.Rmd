---
title: "Adaptive Binning 1/21 Simulations"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE, warnings=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message = FALSE, error=FALSE)
setwd("/home/marco/Dropbox/Duke/projects/FLAME-binning/Adaptive-Binning/")
source("AB_MIPs.R")
library(ggplot2)
library(reshape2)
library(dbarts)
library(RColorBrewer)
require(dbarts)
require(MatchIt)
require(beepr)
require(cem)
require(tidyverse)
source("sims.R")
#source("AB_MIP.R")
set.seed(42069)
```

## 1-D Example MIQP-Variance

```{r "simple MIQP-V p=1", cache=TRUE, results='hide'}
n = 100
n_train = n
n_test = n
p = 1
x_train = matrix(rexp(n*p, 2), n, p)
y_train = rowSums(log(x_train)) + rnorm(n, 0, 1)
x_test = matrix(rexp(n*p, 2), n, p)
y_test = rowSums(log(x_test)) + rnorm(n, 0, 1)
z_train = rep(1, n)
z_test = rep(0, n_test)
simdata = matrix(NA, n, 3* p + 2)
simdata = data.frame(simdata)
names(simdata) = c(paste("x",1:p, sep=""), 
                   paste("a", 1:p, sep=""), 
                   paste("b", 1:p, sep=""), "y", "yest")
mip_outputs = list()
for (i in 1:n){
  print(i)
  xi = x_test[i,]
  
  t1 = proc.time()[3]
  xg = xgboost(data = x_train, label = y_train, nrounds = 50, verbose = F)
  fhat = predict(xg, newdata = x_test)
  mip_pars = setup_miqp_fhat(xi = xi, fhat = fhat,  x_test =  x_test, 
                             lambda=2, alpha=1, beta=0, m=1, M=1e5)
  t2 = proc.time()[3]
  sol = Rcplex(cvec=mip_pars$cvec, Amat=mip_pars$Amat, Qmat = mip_pars$Qmat,
               bvec=mip_pars$bvec, sense = mip_pars$sense,
               lb=mip_pars$lb, ub=mip_pars$ub,
               vtype = mip_pars$vtype, objsense = "max", control = list(trace=0))
  t3 = proc.time()[3]
  
  mip_out = recover_pars(sol, n_train, n_test, p)
  mip_outputs[[i]] = mip_out
  yest = mean(y_test[which(mip_out$w>=0.1)])
  simdata[i, ] = c(xi, mip_out$a, mip_out$b, y_test[i], yest)
  
  t4 = proc.time()[3]
  print(paste("Par generation took", round(t2 - t1, 1), 
              "seconds, solving mip took", round(t3 - t2, 1), "seconds",
              "total:", round(t4 - t1), "seconds"))
  
}
```

```{r "simple MIQP-V p=1 plot"}
ggplot(simdata) + 
  geom_rect(aes(xmin=a1, ymin=min(y), xmax=b1, ymax=max(y)), color="black", size=0.5, alpha=0.3, fill="grey") +
  geom_point(aes(x=x1, y=y), color='red', size=2) + 
  geom_point(aes(x=x1, y=yest), color="blue") + 
  geom_point(data=data.frame(x_train, y_train),aes(x=x_train, y=y_train), pch=18) +
  xlab("x") + ylab("y") + theme_bw() + 
  theme(legend.position = c(0.8,0.2), legend.background = element_rect(color="black", size=0.5),
        legend.title = element_blank())

```

## 2D Example MIQP-Variance

```{r "simple MIP-P p=2", cache=TRUE, results='hide'}
n = 100
n_train = 100
n_test = 100
p = 2
#x_train = matrix(rexp(n_train*p, 2), n_train, p)
#x_test = matrix(rexp(n_test*p, 2), n_test, p)
x_train = matrix(runif(n_train*p, 0, 1), n_train, p)
x_test = matrix(runif(n_test*p, 0, 1), n_test, p)
y_train = rowSums(log(x_train)) + rnorm(n_train, 0, 1)
y_test = rowSums(log(x_test)) + rnorm(n_test, 0, 1)
z_train = rep(1, n_train)
z_train[sample(1:n_train, n_train/2, replace = FALSE)] = 0
z_test = rep(0, n_test)
simdata = matrix(NA, n_test, 3* p + 2)
simdata = data.frame(simdata)
names(simdata) = c(paste("x",1:p, sep=""), 
                   paste("a", 1:p, sep=""), 
                   paste("b", 1:p, sep=""), "y", "yest")
t1 = proc.time()[3]
# xg = xgboost(data = x_train, label = y_train, nrounds = 50, verbose = F)
# fhat = predict(xg, newdata = x_test)
bart_fit = bart(x_train, y_train, x_test, keeptrees = T, verbose = 0)
fhat = colMeans(predict(bart_fit, test=x_test))
obj = rep(NA, n_test)
mip_outputs = list()
for (i in 1:n_test){
  message(paste("Matching unit", i, "of", n_test), "\r", appendLF = FALSE); flush.console()
  xi = x_test[i,]
  mip_pars = setup_miqp_fhat(xi = xi, fhat1 = fhat[-i], fhat0=fhat[-i], 
                             fhati1=fhat[i], fhati0=fhat[i], 
                             z_test=z_test[-i],
                             x_test =  x_test[-i, ], 
                             lambda1=3, lambda0=3, gamma1=5, gamma0=5, 
                             alpha=0, beta=1, m=1, M=1e5)
  sol = Rcplex(cvec=mip_pars$cvec, Amat=mip_pars$Amat, Qmat = mip_pars$Qmat,
               bvec=mip_pars$bvec, sense = mip_pars$sense,
               lb=mip_pars$lb, ub=mip_pars$ub,
               vtype = mip_pars$vtype, objsense = "max", control=list(trace=0))
  mip_out = recover_pars(sol, n_train, n_test-1, p)
  obj[i] = sol$obj
  mip_outputs[[i]] = mip_out
  yest = mean(y_test[-i][which(mip_out$w>=0.1)])
  simdata[i, ] = c(xi, mip_out$a, mip_out$b, y_test[i], yest)
}
print(paste("100 matches took", round(proc.time()[3] - t1, 1)))
```

```{r "simple MIP-P p=2 plot"}
ggplot(simdata) + 
  geom_rect(aes(xmin=a1, ymin=a2, xmax=b1, ymax=b2), fill="grey", 
            color="black", size=0.5, alpha=0.3) + 
  geom_point(aes(x=x1, y=x2, color=abs(yest - y)/mean(abs(y))), size=2) + 
  scale_color_gradient(low="blue", high="red") + 
  xlab("x1") + ylab("x2") +  labs(color="% Abs. error") +  theme_bw() + 
  theme(legend.position = c(0.9,0.5), 
        legend.background = element_rect(color="black", size=0.5))
#ggsave("01-21_p=2_plot.png")
```

```{r}
simdata %<>% mutate(id = 1:nrow(.))
p <- 
    ggplot(data = simdata) + 
    geom_rect_interactive(aes(xmin = a1, xmax = b1, ymin = a2, ymax = b2,
                              data_id = id),
              fill = 'grey', color = 'NA', 
              size = 0.5, alpha = 0) + 
    geom_point_interactive(aes(x = x1, y = x2, 
                               color=abs(yest - y)/mean(abs(y)), data_id = id)) + 
  scale_color_gradient(low="blue", high="red") +
  labs(x = 'x1', y = 'x2', color = "% Abs. Error") +
  theme_bw()
#E8C3D6
#D8CADE
#E9CCD1
girafe(ggobj = p,
         options = list(
           opts_hover(
           css = girafe_css(
             css = 'fill:orange',
             area = 'fill:#E8C3D6;fill-opacity:0.8',
             point = 'fill:black;r:5;stroke:black'
         ))))

# ggplot(simdata) + 
#   geom_rect_interactive(aes(xmin=a1, ymin=a2, xmax=b1, ymax=b2), fill="grey", 
#             color="black", size=0.5, alpha=0.3) + 
#   geom_point(aes(x=x1, y=x2, color=abs(yest - y)/mean(abs(y))), size=2) + 
#   scale_color_gradient(low="blue", high="red") + 
#   xlab("x1") + ylab("x2") +  labs(color="% Abs. error") +  theme_bw() + 
#   theme(legend.position = c(0.9,0.5), 
#         legend.background = element_rect(color="black", size=0.5))
#ggsave("01-21_p=2_plot.png")
```




## 2D Example With a Useless Covariate

```{r "simple MIP-P p=2", cache=TRUE, results='hide'}
n = 100
n_train = 100
n_test = 100
p = 2
x_train = matrix(runif(n_train*p, 0, 1), n_train, p)
y_train = (2*(x_train[, 1])) + rnorm(n_train, 0, 0.5)
x_test = matrix(runif(n_test*p, 0, 1), n_test, p)
y_test = (2*(x_test[, 1])) + rnorm(n_test, 0, 0.5)
z_train = rep(1, n_train)
z_train[sample(1:n_train, n_train/2, replace = FALSE)] = 0
z_test = rep(0, n_test)
simdata = matrix(NA, n_test, 3* p + 2)
simdata = data.frame(simdata)
names(simdata) = c(paste("x",1:p, sep=""), 
                   paste("a", 1:p, sep=""), 
                   paste("b", 1:p, sep=""), "y", "yest")
t1 = proc.time()[3]
# xg = xgboost(data = x_train, label = y_train, nrounds = 50, verbose = F)
# fhat = predict(xg, newdata = x_test)
lasso = glmnet(x_train, y_train, family="gaussian", alpha=1)
fhat = predict(lasso, newx = x_test)[,57]
mip_outputs = list()
for (i in 1:n_test){
  message(paste("Matching unit", i, "of", n_test), "\r", appendLF = FALSE); flush.console()
  xi = x_test[i,]
  mip_pars = setup_miqp_fhat(xi = xi, fhat1 = fhat[-i], fhat0=fhat[-i], 
                             fhati1=fhat[i], fhati0=fhat[i], 
                             z_test=z_test[-i],
                             x_test =  x_test[-i, ], 
                             lambda1=1, lambda0=1, gamma1=2, gamma0=2, 
                             alpha=-1, beta=0, m=1, M=1e5)
  sol = Rcplex(cvec=mip_pars$cvec, Amat=mip_pars$Amat, Qmat = mip_pars$Qmat,
               bvec=mip_pars$bvec, sense = mip_pars$sense,
               lb=mip_pars$lb, ub=mip_pars$ub,
               vtype = mip_pars$vtype, objsense = "max", control=list(trace=0))
  mip_out = recover_pars(sol, n_train, n_test-1, p)
  mip_outputs[[i]] = mip_out
  yest = mean(y_test[-i][which(mip_out$w>=0.1)])
  simdata[i, ] = c(xi, mip_out$a, mip_out$b, y_test[i], yest)
}
print(paste("100 matches took", round(proc.time()[3] - t1, 1)))
```

```{r "simple MIP-P p=2 plot"}
ggplot(simdata) + 
  geom_rect(aes(xmin=a1, ymin=a2, xmax=b1, ymax=b2), fill="grey", 
            color="black", size=0.5, alpha=0.3) + 
  geom_point(aes(x=x1, y=x2, color=abs(yest - y)/mean(abs(y))), size=2) + 
  scale_color_gradient(low="blue", high="red") + 
  xlab("x1") + ylab("x2") +  labs(color="% Abs. error") +  theme_bw() + 
  theme(legend.position = c(0.9,0.5), 
        legend.background = element_rect(color="black", size=0.5))
#ggsave("01-21_p=2_plot.png")
```


# Simulation 1

\begin{align*}
p = 2\\
x_{ij} &\sim Uniform(-3, 3)\\
e_i &= logit(\mathbf{x}_i^T\beta)\\
z_i &\sim Bernoulli(e_i)\\
\epsilon_i &\sim Normal(0, 1)\\
Y_i &= \alpha + z_i \mathbb{I}_{x_{i1} > 0.5}5 + \epsilon_i.
\end{align*}

```{r "sim 1", cache=T}
x_dgp = function(n, p){
  return(matrix(rexp(n*p, 2), n, p))
}
res = matching_sim(10, 200, 3, lambda=4, alpha=-1, beta=0, gamma=0, lambda0=1, lambda1=1, 
                   gamma0=2, gamma1=2, X_dgp=x_dgp, m = 2,
                   estimators = c("MIQP-Fhat", "Greedy", "CEM", "Full Matching" , 
                                  "Nearest Neighbor", "Prognostic", "Mahalanobis"))
res$estimator = factor(res$estimator, levels=c("MIQP-Fhat", "Greedy", "CEM", "Full Matching" , 
                                               "Nearest Neighbor", "Prognostic", "Mahalanobis"))
```

```{r "sim 1 plot"}
CATE_error_plot(res)
```


# Simulation 2

\begin{align*}
p = 10\\
x_{ij} &\sim Uniform(-3, 3)\\
e_i &= logit(\mathbf{x}_i^T\beta)\\
z_i &\sim Bernoulli(e_i)\\
\epsilon_i &\sim Normal(0, 1)\\
Y_i &= \alpha + z_i \mathbb{I}_{x_{i1} > 0.5}5 + \epsilon_i.
\end{align*}

```{r "sim 2", cache=T}
res = matching_sim(10, 200, 10)
res$estimator = factor(res$estimator, levels=c("MIP-Explain", "MIP-Predict", "MIQP-Variance", "Greedy", "CEM", "Full Matching" , "Nearest Neighbor", "Prognostic", "Mahalanobis"))
```

```{r "sim 2 plot"}
CATE_error_plot(res)
```


# Simulation Vittorio
```{r}
X_dgp = function(n, p){
  matrix(runif(n * p, min = 0, max = 5), n, p)
}
y_dgp <- function(x, z, eps, n_irrelevant = 8) {
  p <- ncol(x) - n_irrelevant

  # beta <- rnorm(p, 1.5, 0.15 ^ 0.5)
  beta_tilde <- 5
  Y <- 
    beta_tilde * z + eps
  
  # Y <- rowSums(sweep(x, 2, alpha, '*')) + z * rowSums(sweep(x, 2, beta, '*')) +  
  #   z * (x[, 1] * x[, 2] + x[, 1] * x[, 3] + x[, 2] * x[, 3]) + eps
  return(Y)
}
res <- matching_sim(10, 200, 5, X_dgp = X_dgp, y_dgp = y_dgp,
                   estimators =  c('MIQP-Fhat', 'Greedy', 'Nearest Neighbor', 'CEM', 'Full Matching', 'Prognostic', 'Mahalanobis'))
res$estimator %<>% factor(levels = c('Greedy', 'Nearest Neighbor', 'CEM', 'Full Matching', 'Prognostic', 'Mahalanobis'))
CATE_error_plot(res)
```


# Simulation 3

\begin{align*}
p = 3\\
x_{ij} &\sim exponential(0.5)\\
e_i &= logit(\mathbf{x}_i^T\beta)\\
z_i &\sim Bernoulli(e_i)\\
\epsilon_i &\sim Normal(0, 1)\\
Y_i &= \alpha + z_i \mathbb{I}_{x_{i1} > 0.5}5 + \epsilon_i.
\end{align*}

```{r "sim 3", cache=T}
X_dgp = function(n, p){
  matrix(runif(n * p, min = 0, max = 5), n, p)
}
y_dgp <- function(x, z, eps) {
  p <- ncol(x) - 3 # 3 irrelevant covariates
  alpha <- rnorm(p, 10 * sample(c(-1, 1), 1), 1)
  beta <- rnorm(p, 1.5, 0.15 ^ 0.5)
  Y <- rowSums(sweep(x, 2, alpha, '*')) + z * rowSums(sweep(x, 2, beta, '*')) +  
    z * (x[, 1] * x[, 2] + x[, 1] * x[, 3] + x[, 2] * x[, 3]) + eps
  return(Y)
}
res = matching_sim(10, 200, 6, X_dgp = X_dgp, y_dgp = y_dgp,
                   estimators =  c('MIQP-Fhat', 'Greedy', 'Nearest Neighbor', 'CEM', 'Full Matching', 'Prognostic', 'Mahalanobis'))
res$estimator %<>% factor(levels = c('MIQP-Fhat', 'Greedy', 'Nearest Neighbor', 'CEM', 'Full Matching', 'Prognostic', 'Mahalanobis'))
CATE_error_plot(res)
```



# Simulation 4

\begin{align*}
p = 3\\
x_{ij} &\sim uniform(0.5)\\
e_i &= logit(\mathbf{x}_i^T\beta)\\
z_i &\sim Bernoulli(e_i)\\
\epsilon_i &\sim Normal(0, 1)\\
\mathbf{B} &= diag([0, 2, 1])\\
Y_i &= 2 + 5z_i + z_i\mathbf{x}^T\mathbf{B}\mathbf{x} + \epsilon_i.
\end{align*}

```{r "sim 4", cache=T}
y_dgp = function(X, Z, eps){
  B = diag(c(0, 2, 1))
  HTE = (Z * apply(X, 1, function(x) x %*% B %*% x))
  return(2 + 5 * Z + HTE + eps)
}
x_dgp = function(n, p){
  return(matrix(runif(n*p, 0, 1), n, p))
}
# res = matching_sim(10, 200, 3, y_dgp=y_dgp,lambda=4, alpha=2, beta=0, gamma=0, m=2)
# res$estimator = factor(res$estimator, levels=c("MIP-Explain", "MIP-Predict", "MIQP-Variance", 
#                                                "Greedy", "CEM", "Full Matching" , "Nearest Neighbor", 
#                                                "Prognostic", "Mahalanobis"))
res = matching_sim(10, 200, 3, lambda=4, alpha=-2, beta=0, gamma=0, y_dgp = y_dgp, X_dgp = x_dgp,
                   lambda0=1, lambda1=1, gamma1=2, gamma0=2, m=2,
                   estimators = c("MIQP-Fhat", "Greedy", "CEM", "Full Matching" , 
                                  "Nearest Neighbor", "Prognostic", "Mahalanobis"))
res$estimator = factor(res$estimator, levels=c("MIQP-Fhat", "Greedy", "CEM", "Full Matching" , 
                                               "Nearest Neighbor", "Prognostic", "Mahalanobis"))
```

```{r "sim 4 plot"}
CATE_error_plot(res)
```


# Simulation 5

\begin{align*}
p = 10\\
x_{ij} &\sim uniform(0.5)\\
e_i &= logit(\mathbf{x}_i^T\beta)\\
z_i &\sim Bernoulli(e_i)\\
\epsilon_i &\sim Normal(0, 1)\\
\mathbf{B} &= diag([0, 2, 1, 0, 0, 1, 1, 2, 3, 0])\\
Y_i &= 2 + 5z_i + z_i\mathbf{x}_i^T\mathbf{B}\mathbf{x}_i + \epsilon_i.
\end{align*}

```{r "sim 5", cache=T}
HTE_dgp = function(X, Z){
  B = diag(c(0, 2, 1, 0, 0, 1, 1, 2, 3, 0))
  return(Z * apply(X, 1, function(x) x %*% B %*% x))
}
y_dgp = function(X, Z, HTE){
  return(2 + 5 * Z + HTE + rnorm(nrow(X), 0, 1))
}
res = matching_sim(10, 200, 10, HTE_dgp = HTE_dgp, y_dgp=y_dgp)
res$estimator = factor(res$estimator, levels=c("MIP-Explain", "MIP-Predict", "MIQP-Variance", 
                                               "Greedy", "CEM", "Full Matching" , "Nearest Neighbor", 
                                               "Prognostic", "Mahalanobis"))
```

```{r "sim 5 plot"}
CATE_error_plot(res)
```


# Simulation 6

\begin{align*}
p = 3\\
x_{ij} &\sim uniform(0.5)\\
e_i &= logit(\mathbf{x}_i^T\beta)\\
z_i &\sim Bernoulli(e_i)\\
\epsilon_i &\sim Normal(0, 1)\\
\mathbf{B} &= diag([0, 2, 1])\\
Y_i &= 2 + 5z_i + z_i\mathbf{x}_i^T\mathbf{B}\mathbf{x}_i + \mathbf{x}_i^t\gamma + \epsilon_i.
\end{align*}

```{r "sim 6", cache=T}
y_dgp = function(X, Z, eps){
  gamma = c(2,0,1)
  B = diag(c(0,2,1))
  return(2 + 5 * Z + Z * apply(X, 1, function(x) x %*% B %*% x) + as.matrix(X) %*% gamma + eps)
}
res = matching_sim(10, 200, 3, y_dgp=y_dgp)
res$estimator = factor(res$estimator, levels=c("MIP-Explain", "MIP-Predict", "MIQP-Variance", 
                                               "Greedy", "CEM", "Full Matching" , "Nearest Neighbor", 
                                               "Prognostic", "Mahalanobis"))
```

```{r "sim 6  plot"}
CATE_error_plot(res)
```



# Simulation 7

\begin{align*}
p = 5\\
x_{ij} &\sim uniform(0.5)\\
e_i &= logit(\mathbf{x}_i^T\beta)\\
z_i &\sim Bernoulli(e_i)\\
\epsilon_i &\sim Normal(0, 1)\\
\mathbf{B} &= diag([0, 2, 1])\\
Y_i &= 2 + 5z_i + z_i\mathbf{x}_i^T\mathbf{B}\mathbf{x}_i + \mathbf{x}_i^t\gamma + \epsilon_i.
\end{align*}

```{r "sim 7", cache=T}
x_dgp = function(n, p){
  return(matrix(runif(n*p, 0, 1), n, p))
}
y_dgp = function(X, Z, eps){
  HTE = 10 * sin(pi * X[, 1]*X[, 2]) + 20 * (X[, 3] - 0.5)^2 + 10 * X[, 4] + 5 * X[, 5]
  return (2 + HTE + Z*5 + eps)
}
res = matching_sim(10, 200, 5, lambda=4, alpha=-2, beta=0, gamma=0, y_dgp = y_dgp, X_dgp = x_dgp,
                   lambda0=1, lambda1=1, gamma1=2, gamma0=2, m=2,
                   estimators = c("MIQP-Fhat", "Greedy", "CEM", "Full Matching" , 
                                  "Nearest Neighbor", "Prognostic", "Mahalanobis"))
res$estimator = factor(res$estimator, levels=c("MIQP-Fhat","Greedy", "CEM", "Full Matching" , "Nearest Neighbor", 
                                               "Prognostic", "Mahalanobis"))
```

```{r "sim 7  plot"}
CATE_error_plot(res)
```


# Hyperparam Comparisons

```{r "hp comparison", cache=TRUE}
lambdas = 1:5
alphas = -5:5
simdata = NULL
for(lambda in lambdas){
  for (alpha in alphas){
    res = matching_sim(5 , 100, p=3, alpha=alpha, lambda=lambda)
    res = summarize_CATEs(res)
    simdata = rbind(simdata, data.frame(res, lambda=rep(lambda, nrow(res)), alpha=rep(alpha, nrow(res))))
  }
}
```

```{r "hp plot"}
ggdata =simdata[simdata$estimator %in% c("MIP-Explain", "MIP-Predict", "MIQP-Variance"), ]
ggplot(ggdata) + geom_point(aes(x=alpha, y=MSE, color=estimator)) + facet_grid(lambda~.)
```


# MG Analysis

## DGP 1

```{r "MG analysis", cache=TRUE}
c(df, HTE_true) %<-% simulate_data(200, 3)
c(df, f, n, n_train, p,
    train_df, train_covs, train_control, train_treated,
    test_df, test_covs, test_control, test_treated, 
    n_test_control, n_test_treated, 
    bart_fit, counterfactuals) %<-% estimator_inputs(df, 100, 200)
c(greedy_cates, greedy_bins) %<-% est_greedy(train_df, test_df, test_covs, test_control, test_treated,
                                             n_test_treated, 3, bart_fit)
c(miqp_cates, miqp_bins) %<-% est_MIQP_fhat(test_df, test_treated, n_test_treated, test_covs, bart_fit, 
                                            n_train, p, lambda=3, alpha=0, m=2)

miqp_cates2 = rep(NA, n_test_treated)
for (i in 1:n_test_treated){
  mg = make_mg(test_covs, miqp_bins[i,,1], miqp_bins[i,,2])
  miqp_cates2[i] = mean(test_df$Y[mg][test_df$treated[mg]]) - mean(test_df$Y[mg][!test_df$treated[mg]])
}

HTE_tt = HTE_true[test_treated]

ge = abs(HTE_tt - greedy_cates)
me = abs(HTE_tt - miqp_cates)
me2 = abs(miqp_cates2 - HTE_tt)

mip_pars =  setup_miqp_variance(xi = as.numeric(test_covs[i, ]),
                                    y_train = train_df$Y,
                                    x_train = train_covs,
                                    z_train = train_df$treated,
                                    x_test = as.matrix(test_covs[test_df$treated==0, ]),  
                                    alpha=alpha, lambda=lambda, m=m, M=M)
sol <- do.call(Rcplex, c(mip_pars, list(objsense="max", control=list(trace=0))))
mip_out = recover_pars(sol, nrow(train_df), sum(test_df$treated==0), p)
    
```


## DGP 2

```{r "MG analysis", cache=TRUE}
y_dgp = function(X, Z, eps){
  B = diag(c(0, 2, 1))
  HTE = (Z * apply(X, 1, function(x) x %*% B %*% x))
  gamma = c(0, 2, 1)
  return(2 + 5 * Z + HTE + X%*%gamma + eps)
}
x_dgp = function(n, p){
  return(matrix(runif(n*p, 0, 1), n, p))
}
c(df, HTE) %<-% simulate_data(200, 3, y_dgp = y_dgp, X_dgp=x_dgp)
c(df, f, n, n_train, p,
    train_df, train_covs, train_control, train_treated,
    test_df, test_covs, test_control, test_treated, 
    n_test_control, n_test_treated, 
    bart_fit, counterfactuals) %<-% estimator_inputs(df, 100, 200)
HTE_test_treated = HTE[test_treated]
c(greedy_cates, greedy_bins) %<-% est_greedy(train_df, test_df, test_covs, test_control, test_treated,
                                             n_test_treated, 3, bart_fit)
c(miqp_cates, miqp_bins) %<-% est_MIQP_fhat(test_df, test_treated, n_test_treated, test_covs, bart_fit, 
                                            n_train, p, 
                                            lambda0=1, lambda1=1, gamma0=0.5, gamma1=0.5,
                                            alpha=-1, beta=2, m=1)

miqp_mq = rep(NA, n_test_treated)
greedy_mq = rep(NA, n_test_treated)
for (i in 1:n_test_treated){
  mg = make_mg(test_covs, miqp_bins[i,,1], miqp_bins[i,,2])
  miqp_mq[i] = mean(abs(colMeans(test_covs[mg, ][test_df$treated[mg],]) - 
                          colMeans(test_covs[mg, ][!test_df$treated[mg],])))
  mg = make_mg(test_covs, greedy_bins[i,,1], greedy_bins[i,,2])
  greedy_mq[i] = mean(abs(colMeans(test_covs[mg, ][test_df$treated[mg],]) - 
                          colMeans(test_covs[mg, ][!test_df$treated[mg],])))
}

ge = abs(HTE_test_treated - greedy_cates)
me = abs(HTE_test_treated - miqp_cates)

print(mean(me))

mip_pars =  setup_miqp_variance(xi = as.numeric(test_covs[i, ]),
                                    y_train = train_df$Y,
                                    x_train = train_covs,
                                    z_train = train_df$treated,
                                    x_test = as.matrix(test_covs[test_df$treated==0, ]),  
                                    alpha=alpha, lambda=lambda, m=m, M=M)
sol <- do.call(Rcplex, c(mip_pars, list(objsense="max", control=list(trace=0))))
mip_out = recover_pars(sol, nrow(train_df), sum(test_df$treated==0), p)
    
```


## Simple Tests
```{r "Simple test"}

```




